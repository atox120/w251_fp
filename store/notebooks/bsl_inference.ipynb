{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a7aed7-6b2a-4081-8ed3-7847c97ac7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../Video-Swin-Transformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5c1440-6b87-41d0-814a-b275108a97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change teh working directory to a location that the code prefers\n",
    "os.chdir(\"../Video-Swin-Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e4a28c-4e43-4cde-8e9a-3d7236acb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import warnings\n",
    "import argparse\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import mmcv\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.cnn import fuse_conv_bn\n",
    "from mmcv.fileio.io import file_handlers\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import get_dist_info, init_dist, load_checkpoint\n",
    "from mmcv.runner.fp16_utils import wrap_fp16_model\n",
    "\n",
    "from mmaction.models import build_model\n",
    "from mmaction.utils import register_module_hooks\n",
    "from mmaction.datasets import build_dataloader, build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "befe8d30-137b-48ee-8fff-5f6c81f50d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import test functions from mmcv and delete them from mmaction2\n",
    "try:\n",
    "    from mmcv.engine import multi_gpu_test, single_gpu_test\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    warnings.warn(\n",
    "        'DeprecationWarning: single_gpu_test, multi_gpu_test, '\n",
    "        'collect_results_cpu, collect_results_gpu from mmaction2 will be '\n",
    "        'deprecated. Please install mmcv through master branch.')\n",
    "    from mmaction.apis import multi_gpu_test, single_gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4af724e-036d-455e-bfa4-c6f354e968b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the cofiguration and data file\n",
    "config_file = '../configs/bsl_config.py'\n",
    "check_point_file = './work_dirs/k400_swin_tiny_patch244_window877.py/best_top1_acc_epoch_10.pth'\n",
    "cmd_options = [config_file, check_point_file, \"--eval\", \"top_k_accuracy\", \"--average-clips\", \"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d645547d-3733-4567-9634-ef5e9d4608eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(parse_options=None):\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='MMAction2 test (and eval) a model')\n",
    "    parser.add_argument('config', help='test config file path')\n",
    "    parser.add_argument('checkpoint', help='checkpoint file')\n",
    "    parser.add_argument(\n",
    "        '--out',\n",
    "        default=None,\n",
    "        help='output result file in pkl/yaml/json format')\n",
    "    parser.add_argument(\n",
    "        '--fuse-conv-bn',\n",
    "        action='store_true',\n",
    "        help='Whether to fuse conv and bn, this will slightly increase'\n",
    "        'the inference speed')\n",
    "    parser.add_argument(\n",
    "        '--eval',\n",
    "        type=str,\n",
    "        nargs='+',\n",
    "        help='evaluation metrics, which depends on the dataset, e.g.,'\n",
    "        ' \"top_k_accuracy\", \"mean_class_accuracy\" for video dataset')\n",
    "    parser.add_argument(\n",
    "        '--gpu-collect',\n",
    "        action='store_true',\n",
    "        help='whether to use gpu to collect results')\n",
    "    parser.add_argument(\n",
    "        '--tmpdir',\n",
    "        help='tmp directory used for collecting results from multiple '\n",
    "        'workers, available when gpu-collect is not specified')\n",
    "    parser.add_argument(\n",
    "        '--options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        default={},\n",
    "        help='custom options for evaluation, the key-value pair in xxx=yyy '\n",
    "        'format will be kwargs for dataset.evaluate() function (deprecate), '\n",
    "        'change to --eval-options instead.')\n",
    "    parser.add_argument(\n",
    "        '--eval-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        default={},\n",
    "        help='custom options for evaluation, the key-value pair in xxx=yyy '\n",
    "        'format will be kwargs for dataset.evaluate() function')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        default={},\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. For example, '\n",
    "        \"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\")\n",
    "    parser.add_argument(\n",
    "        '--average-clips',\n",
    "        choices=['score', 'prob', None],\n",
    "        default=None,\n",
    "        help='average type when averaging test clips')\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    parser.add_argument(\n",
    "        '--onnx',\n",
    "        action='store_true',\n",
    "        help='Whether to test with onnx model or not')\n",
    "    parser.add_argument(\n",
    "        '--tensorrt',\n",
    "        action='store_true',\n",
    "        help='Whether to test with TensorRT engine or not')\n",
    "    \n",
    "    if parse_options is None: \n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(parse_options)\n",
    "        \n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    if args.options and args.eval_options:\n",
    "        raise ValueError(\n",
    "            '--options and --eval-options cannot be both '\n",
    "            'specified, --options is deprecated in favor of --eval-options')\n",
    "    if args.options:\n",
    "        warnings.warn('--options is deprecated in favor of --eval-options')\n",
    "        args.eval_options = args.options\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fcf1268-7cf9-43a7-8f3b-ed7a2265c191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py\n",
      "../Video-Swin-Transformer/configs/_base_/default_runtime.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parse_args(cmd_options)\n",
    "\n",
    "if args.tensorrt and args.onnx:\n",
    "    raise ValueError(\n",
    "        'Cannot set onnx mode and tensorrt mode at the same time.')\n",
    "\n",
    "# Get the conifguration from the file\n",
    "cfg = Config.fromfile(args.config)\n",
    "cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "# Customization for training the BSL data set\n",
    "cfg.model.cls_head.num_classes = 5\n",
    "\n",
    "# Load output_config from cfg\n",
    "output_config = cfg.get('output_config', {})\n",
    "if args.out:\n",
    "    # Overwrite output_config from args.out\n",
    "    output_config = Config._merge_a_into_b(dict(out=args.out), output_config)\n",
    "\n",
    "# Load eval_config from cfg\n",
    "eval_config = cfg.get('eval_config', {})\n",
    "if args.eval:\n",
    "    # Overwrite eval_config from args.eval\n",
    "    eval_config = Config._merge_a_into_b(dict(metrics=args.eval), eval_config)\n",
    "    \n",
    "if args.eval_options:\n",
    "    # Add options from args.eval_options\n",
    "    eval_config = Config._merge_a_into_b(args.eval_options, eval_config)\n",
    "\n",
    "\n",
    "assert output_config or eval_config, ('Please specify at least one operation (save or eval the '\n",
    "     'results) with the argument \"--out\" or \"--eval\"')\n",
    "\n",
    "dataset_type = cfg.data.test.type\n",
    "if output_config.get('out', None):\n",
    "    if 'output_format' in output_config:\n",
    "        # ugly workround to make recognition and localization the same\n",
    "        warnings.warn('Skip checking `output_format` in localization task.')\n",
    "    else:\n",
    "        out = output_config['out']\n",
    "        # make sure the dirname of the output path exists\n",
    "        mmcv.mkdir_or_exist(osp.dirname(out))\n",
    "        _, suffix = osp.splitext(out)\n",
    "        if dataset_type == 'AVADataset':\n",
    "            assert suffix[1:] == 'csv', ('For AVADataset, the format of '\n",
    "                                         'the output file should be csv')\n",
    "        else:\n",
    "            assert suffix[1:] in file_handlers, (\n",
    "                'The format of the output '\n",
    "                'file should be json, pickle or yaml')\n",
    "\n",
    "\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "# The flag is used to register module's hooks\n",
    "cfg.setdefault('module_hooks', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f277434f-548f-432c-b580-ac125de9de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4d0518a-b6aa-4f3f-9fd9-df2461458d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataloader\n",
    "dataset = build_dataset(cfg.data.test, dict(test_mode=True))\n",
    "\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    dist=distributed,\n",
    "    shuffle=False)\n",
    "dataloader_setting = dict(dataloader_setting, **cfg.data.get('test_dataloader', {}))\n",
    "data_loader = build_dataloader(dataset, **dataloader_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9222a22-a620-4a6b-bf10-9970a297eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ca04999-93b3-431e-97d9-f4d50b686cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['imgs'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04fbccfe-3e51-42d5-a955-0be1b4ac7da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_off_pretrained(cfg):\n",
    "    # recursively find all pretrained in the model config,\n",
    "    # and set them None to avoid redundant pretrain steps for testing\n",
    "    if 'pretrained' in cfg:\n",
    "        cfg.pretrained = None\n",
    "\n",
    "    # recursively turn off pretrained value\n",
    "    for sub_cfg in cfg.values():\n",
    "        if isinstance(sub_cfg, dict):\n",
    "            turn_off_pretrained(sub_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8341621-2979-4c65-b978-6cd1bc4893de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2166.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: ./work_dirs/k400_swin_tiny_patch244_window877.py/best_top1_acc_epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "# remove redundant pretrain steps for testing\n",
    "turn_off_pretrained(cfg.model)\n",
    "\n",
    "# build the model and load checkpoint\n",
    "model = build_model(cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "if len(cfg.module_hooks) > 0:\n",
    "    register_module_hooks(model, cfg.module_hooks)\n",
    "\n",
    "fp16_cfg = cfg.get('fp16', None)\n",
    "if fp16_cfg is not None:\n",
    "    wrap_fp16_model(model)\n",
    "load_checkpoint(model, args.checkpoint, map_location='cpu')\n",
    "\n",
    "model = MMDataParallel(model, device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a30d4c3-5752-49ed-8814-7746a1395aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'Recognizer3D',\n",
       " 'backbone': {'type': 'SwinTransformer3D',\n",
       "  'patch_size': (2, 4, 4),\n",
       "  'embed_dim': 96,\n",
       "  'depths': [2, 2, 6, 2],\n",
       "  'num_heads': [3, 6, 12, 24],\n",
       "  'window_size': (8, 7, 7),\n",
       "  'mlp_ratio': 4.0,\n",
       "  'qkv_bias': True,\n",
       "  'qk_scale': None,\n",
       "  'drop_rate': 0.0,\n",
       "  'attn_drop_rate': 0.0,\n",
       "  'drop_path_rate': 0.1,\n",
       "  'patch_norm': True},\n",
       " 'cls_head': {'type': 'I3DHead',\n",
       "  'in_channels': 768,\n",
       "  'num_classes': 5,\n",
       "  'spatial_type': 'avg',\n",
       "  'dropout_ratio': 0.5},\n",
       " 'test_cfg': {'average_clips': 'prob', 'max_testing_views': 4}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b291b111-0542-4d4d-889d-9847b2b2edac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': [123.675, 116.28, 103.53],\n",
       " 'std': [58.395, 57.12, 57.375],\n",
       " 'to_bgr': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.img_norm_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac3b4219-32f9-4a47-8abe-14ed185b2151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 10/10, 0.3 task/s, elapsed: 33s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "# These are the expected outputs from the dataset\n",
    "expected_classes = [x['label'] for x in dataset.video_infos]\n",
    "\n",
    "# These are the actual outputs\n",
    "outputs = single_gpu_test(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9647acb-e8be-47f6-9b09-b49d9a33e7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating top_k_accuracy ...\n",
      "\n",
      "top1_acc\t1.0000\n",
      "top5_acc\t1.0000\n",
      "top1_acc: 1.0000\n",
      "top5_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, 0, 0],\n",
       "       [0, 2, 0, 0, 0],\n",
       "       [0, 0, 2, 0, 0],\n",
       "       [0, 0, 0, 2, 0],\n",
       "       [0, 0, 0, 0, 2]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of results\n",
    "eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "for name, val in eval_res.items():\n",
    "    print(f'{name}: {val:.04f}')\n",
    "\n",
    "predicted_classes = [np.argmax(x) for x in outputs]\n",
    "confusion_matrix(expected_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ccca34f-08f8-4163-8c88-a0215fb21f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.reshape(cfg.img_norm_cfg['mean'], [len(cfg.img_norm_cfg['mean']), 1, 1])\n",
    "std = np.reshape(cfg.img_norm_cfg['std'], [len(cfg.img_norm_cfg['std']), 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3afb183a-4b73-4f71-9236-1eb3a29961d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f85b47d2-b095-4256-a081-d88f9b2ba942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "predicted_classes = np.array(predicted_classes)\n",
    "expected_classes = np.array(expected_classes)\n",
    "\n",
    "# These are were the predictions were incorrect\n",
    "mismatches = predicted_classes != expected_classes\n",
    "\n",
    "# These are the mismatched images\n",
    "for cl in range(5):\n",
    "    # Location of all the videos that were wrongly classified\n",
    "    index = (expected_classes == cl) & mismatches\n",
    "    # For this class find if there were any mismatches\n",
    "    if np.any(index):\n",
    "        # Get the first set of images\n",
    "        img_loc = np.where(index)[0][0]\n",
    "        vid = dataset[img_loc]['imgs'].numpy()\n",
    "        \n",
    "        # For each set of images\n",
    "        for vid_loc in range(vid.shape[0]):\n",
    "            # This is one video\n",
    "            one_vid = vid[vid_loc, :].squeeze()\n",
    "            \n",
    "            plt.figure(figsize=(4*8, 4*4))\n",
    "            # Now extract each frame from the video\n",
    "            for frm_loc in range(one_vid.shape[1]):\n",
    "                # \n",
    "                one_frm = one_vid[:, frm_loc, :, :].squeeze()\n",
    "                \n",
    "                one_frm *= std\n",
    "                one_frm += mean\n",
    "                \n",
    "                plt.subplot(4, 8, frm_loc+1)\n",
    "                plt.imshow(one_frm.transpose(1, 2, 0).astype('int'))\n",
    "                plt.axis('off')\n",
    "            print(one_frm.shape)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced818e-10bd-43f2-979d-14988312668f",
   "metadata": {},
   "source": [
    "# Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f18329c4-8bf7-4458-8c3e-9cbcd803f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if args.tensorrt:\n",
    "#     outputs = inference_tensorrt(args.checkpoint, distributed, data_loader,\n",
    "#                                  dataloader_setting['videos_per_gpu'])\n",
    "# elif args.onnx:\n",
    "#     outputs = inference_onnx(args.checkpoint, distributed, data_loader,\n",
    "#                              dataloader_setting['videos_per_gpu'])\n",
    "# else:\n",
    "#     outputs = inference_pytorch(args, cfg, distributed, data_loader)\n",
    "\n",
    "# rank, _ = get_dist_info()\n",
    "# if rank == 0:\n",
    "#     if output_config.get('out', None):\n",
    "#         out = output_config['out']\n",
    "#         print(f'\\nwriting results to {out}')\n",
    "#         dataset.dump_results(outputs, **output_config)\n",
    "#     if eval_config:\n",
    "#         eval_res = dataset.evaluate(outputs, **eval_config)\n",
    "#         for name, val in eval_res.items():\n",
    "#             print(f'{name}: {val:.04f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
