{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a7aed7-6b2a-4081-8ed3-7847c97ac7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../Video-Swin-Transformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5c1440-6b87-41d0-814a-b275108a97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change teh working directory to a location that the code prefers\n",
    "os.chdir(\"../Video-Swin-Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e4a28c-4e43-4cde-8e9a-3d7236acb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist, set_random_seed\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmaction import __version__\n",
    "from mmaction.apis import train_model\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.utils import collect_env, get_root_logger, register_module_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea8e512-db21-4cb2-9101-305199748aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c521d7ba-77f0-4cc9-8dd2-9a426f07b409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Log in to your W&B account\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824ca902-3e0b-48f7-8bd2-57db303a9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project_name = 'lamba_bsl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "befe8d30-137b-48ee-8fff-5f6c81f50d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import test functions from mmcv and delete them from mmaction2\n",
    "try:\n",
    "    from mmcv.engine import multi_gpu_test, single_gpu_test\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    warnings.warn(\n",
    "        'DeprecationWarning: single_gpu_test, multi_gpu_test, '\n",
    "        'collect_results_cpu, collect_results_gpu from mmaction2 will be '\n",
    "        'deprecated. Please install mmcv through master branch.')\n",
    "    from mmaction.apis import multi_gpu_test, single_gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "790667cc-bad1-43c0-9df4-a7e86c65dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(parse_options=None):\n",
    "    parser = argparse.ArgumentParser(description='Train a recognizer')\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    parser.add_argument(\n",
    "        '--load-from', help='the checkpoint file to load from')\n",
    "    parser.add_argument(\n",
    "        '--validate',\n",
    "        action='store_true',\n",
    "        help='whether to evaluate the checkpoint during training')\n",
    "    parser.add_argument(\n",
    "        '--test-last',\n",
    "        action='store_true',\n",
    "        help='whether to test the checkpoint after training')\n",
    "    parser.add_argument(\n",
    "        '--test-best',\n",
    "        action='store_true',\n",
    "        help=('whether to test the best checkpoint (if applicable) after '\n",
    "              'training'))\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        default={},\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. For example, '\n",
    "        \"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\")\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    \n",
    "    if parse_options is None: \n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(parse_options)\n",
    "        \n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5baa4b97-74b5-4082-9a12-3cf378f11bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the cofiguration and data file\n",
    "config_file = '../configs/bsl_config.py'\n",
    "check_point_file = '../configs/swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
    "# , \"model.backbone.pretrained=\"+check_point_file\n",
    "# cmd_options = [config_file, \"--cfg-options\", \"model.backbone.use_checkpoint=True\", \"--load-from\", check_point_file,\n",
    "#                \"--seed\", \"12345\"]\n",
    "cmd_options = [config_file, \"--cfg-options\", \"model.backbone.use_checkpoint=True\", \"--load-from\", check_point_file,\n",
    "              \"--validate\", \"--seed\", \"12345\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdd078b-640c-4500-bfb6-737ccde06ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e35d5ede-d413-405f-9fce-5be60ba5183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py\n",
      "../Video-Swin-Transformer/configs/_base_/default_runtime.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:08:25,106 - mmaction - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]\n",
      "CUDA available: True\n",
      "GPU 0,1: NVIDIA GeForce RTX 3090\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Build cuda_11.6.r11.6/compiler.30794723_0\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n",
      "PyTorch: 1.11.0a0+17540c5\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.3.3 (Git Hash N/A)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_86,code=compute_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS=-fno-gnu-unique -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0a0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.4.0\n",
      "MMCV Compiler: GCC 9.3\n",
      "MMCV CUDA Compiler: not available\n",
      "MMAction2: 0.15.0+db018fb\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-04-10 21:08:25,108 - mmaction - INFO - Distributed training: False\n",
      "2022-04-10 21:08:25,331 - mmaction - INFO - Config: model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer3D',\n",
      "        patch_size=(2, 4, 4),\n",
      "        embed_dim=96,\n",
      "        depths=[2, 2, 6, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        window_size=(8, 7, 7),\n",
      "        mlp_ratio=4.0,\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        patch_norm=True,\n",
      "        use_checkpoint=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        in_channels=768,\n",
      "        num_classes=5,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5),\n",
      "    test_cfg=dict(average_clips='prob', max_testing_views=4))\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '../configs/swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1), ('val', 1)]\n",
      "swin_tiny_path = '../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py'\n",
      "runtime_path = '../Video-Swin-Transformer/configs/_base_/default_runtime.py'\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = '../processed_videos'\n",
      "data_root_val = '../processed_videos/val'\n",
      "data_root_test = '../processed_videos/test'\n",
      "data_root_train = '../processed_videos/train'\n",
      "ann_file_val = '../processed_videos/bsl_val_video.txt'\n",
      "ann_file_test = '../processed_videos/bsl_test_video.txt'\n",
      "ann_file_train = '../processed_videos/bsl_train_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 224)),\n",
      "    dict(type='ThreeCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    val_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    test_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_train_video.txt',\n",
      "        data_prefix='../processed_videos/train',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_val_video.txt',\n",
      "        data_prefix='../processed_videos/val',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_test_video.txt',\n",
      "        data_prefix='../processed_videos/test',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 224)),\n",
      "            dict(type='ThreeCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.001,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.02,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            backbone=dict(lr_mult=0.1))))\n",
      "lr_config = dict(\n",
      "    policy='CosineAnnealing',\n",
      "    min_lr=0,\n",
      "    warmup='linear',\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=2.5)\n",
      "total_epochs = 15\n",
      "work_dir = './work_dirs/k400_swin_tiny_patch244_window877.py'\n",
      "find_unused_parameters = False\n",
      "fp16 = None\n",
      "optimizer_config = dict(\n",
      "    type='DistOptimizerHook',\n",
      "    update_interval=4,\n",
      "    grad_clip=None,\n",
      "    coalesce=True,\n",
      "    bucket_size_mb=-1,\n",
      "    use_fp16=True)\n",
      "gpu_ids = range(0, 1)\n",
      "omnisource = False\n",
      "module_hooks = []\n",
      "\n",
      "2022-04-10 21:08:25,332 - mmaction - INFO - Set random seed to 12345, deterministic: False\n"
     ]
    }
   ],
   "source": [
    "# Create a configuration object that describes the training and testing\n",
    "args = parse_args(cmd_options)\n",
    "cfg = Config.fromfile(args.config)\n",
    "cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "# Customization for training the BSL data set\n",
    "# https://mmcv.readthedocs.io/en/latest/_modules/mmcv/runner/epoch_based_runner.html\n",
    "cfg.workflow = [('train', 1), ('val', 1)]\n",
    "# cfg.workflow = [('train', 1), ]\n",
    "cfg.model.cls_head.num_classes = 5\n",
    "\n",
    "# Resume from this pyhton checkpoint file\n",
    "cfg.resume_from = args.resume_from\n",
    "cfg.load_from = args.load_from\n",
    "\n",
    "# One GPU\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "# Omnisource reference: https://arxiv.org/abs/2003.13042\n",
    "cfg.setdefault('omnisource', False)\n",
    "\n",
    "# The flag is used to register module's hooks\n",
    "cfg.setdefault('module_hooks', [])\n",
    "\n",
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# dump config\n",
    "cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))\n",
    "\n",
    "# init logger before other steps\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "# init the meta dict to record some important information such as\n",
    "# environment info and seed, which will be logged\n",
    "meta = dict()\n",
    "# log env info\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([f'{k}: {v}' for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "            dash_line)\n",
    "meta['env_info'] = env_info\n",
    "\n",
    "# log some basic info\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config: {cfg.pretty_text}')\n",
    "\n",
    "# Set seed for training\n",
    "logger.info(f'Set random seed to {args.seed}, '\n",
    "            f'deterministic: {args.deterministic}')\n",
    "set_random_seed(args.seed, deterministic=args.deterministic)\n",
    "\n",
    "cfg.seed = args.seed\n",
    "meta['seed'] = args.seed\n",
    "meta['config_name'] = osp.basename(args.config)\n",
    "meta['work_dir'] = osp.basename(cfg.work_dir.rstrip('/\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f965ec0-5475-4d9e-8680-1750367df750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Validation is setup as a hook that kicks off every 5 iterations\n",
    "# This is required for wandb to kickk off every iteration\n",
    "if 1:\n",
    "    # Create the validation dataset\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    datasets.append(build_dataset(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78afc72a-490e-4cf5-ab6d-1af0f142038f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([1, 3, 32, 224, 224])\n",
      "1 torch.Size([1, 3, 32, 224, 224])\n",
      "2 torch.Size([1, 3, 32, 224, 224])\n",
      "3 torch.Size([1, 3, 32, 224, 224])\n",
      "4 torch.Size([1, 3, 32, 224, 224])\n",
      "5 torch.Size([1, 3, 32, 224, 224])\n",
      "6 torch.Size([1, 3, 32, 224, 224])\n",
      "7 torch.Size([1, 3, 32, 224, 224])\n",
      "8 torch.Size([1, 3, 32, 224, 224])\n",
      "9 torch.Size([1, 3, 32, 224, 224])\n",
      "10 torch.Size([1, 3, 32, 224, 224])\n",
      "11 torch.Size([1, 3, 32, 224, 224])\n",
      "12 torch.Size([1, 3, 32, 224, 224])\n",
      "13 torch.Size([1, 3, 32, 224, 224])\n",
      "14 torch.Size([1, 3, 32, 224, 224])\n",
      "15 torch.Size([1, 3, 32, 224, 224])\n",
      "16 torch.Size([1, 3, 32, 224, 224])\n",
      "17 torch.Size([1, 3, 32, 224, 224])\n",
      "18 torch.Size([1, 3, 32, 224, 224])\n",
      "19 torch.Size([1, 3, 32, 224, 224])\n",
      "20 torch.Size([1, 3, 32, 224, 224])\n",
      "21 torch.Size([1, 3, 32, 224, 224])\n",
      "22 torch.Size([1, 3, 32, 224, 224])\n",
      "23 torch.Size([1, 3, 32, 224, 224])\n",
      "24 torch.Size([1, 3, 32, 224, 224])\n",
      "25 torch.Size([1, 3, 32, 224, 224])\n",
      "26 torch.Size([1, 3, 32, 224, 224])\n",
      "27 torch.Size([1, 3, 32, 224, 224])\n",
      "28 torch.Size([1, 3, 32, 224, 224])\n",
      "29 torch.Size([1, 3, 32, 224, 224])\n",
      "30 torch.Size([1, 3, 32, 224, 224])\n",
      "31 torch.Size([1, 3, 32, 224, 224])\n",
      "32 torch.Size([1, 3, 32, 224, 224])\n",
      "33 torch.Size([1, 3, 32, 224, 224])\n",
      "34 torch.Size([1, 3, 32, 224, 224])\n",
      "35 torch.Size([1, 3, 32, 224, 224])\n",
      "36 torch.Size([1, 3, 32, 224, 224])\n",
      "37 torch.Size([1, 3, 32, 224, 224])\n",
      "38 torch.Size([1, 3, 32, 224, 224])\n",
      "39 torch.Size([1, 3, 32, 224, 224])\n",
      "40 torch.Size([1, 3, 32, 224, 224])\n",
      "41 torch.Size([1, 3, 32, 224, 224])\n",
      "42 torch.Size([1, 3, 32, 224, 224])\n",
      "43 torch.Size([1, 3, 32, 224, 224])\n",
      "44 torch.Size([1, 3, 32, 224, 224])\n",
      "45 torch.Size([1, 3, 32, 224, 224])\n",
      "46 torch.Size([1, 3, 32, 224, 224])\n",
      "47 torch.Size([1, 3, 32, 224, 224])\n",
      "48 torch.Size([1, 3, 32, 224, 224])\n",
      "49 torch.Size([1, 3, 32, 224, 224])\n",
      "50 torch.Size([1, 3, 32, 224, 224])\n",
      "51 torch.Size([1, 3, 32, 224, 224])\n",
      "52 torch.Size([1, 3, 32, 224, 224])\n",
      "53 torch.Size([1, 3, 32, 224, 224])\n",
      "54 torch.Size([1, 3, 32, 224, 224])\n",
      "55 torch.Size([1, 3, 32, 224, 224])\n",
      "56 torch.Size([1, 3, 32, 224, 224])\n",
      "57 torch.Size([1, 3, 32, 224, 224])\n",
      "58 torch.Size([1, 3, 32, 224, 224])\n",
      "59 torch.Size([1, 3, 32, 224, 224])\n",
      "60 torch.Size([1, 3, 32, 224, 224])\n",
      "61 torch.Size([1, 3, 32, 224, 224])\n",
      "62 torch.Size([1, 3, 32, 224, 224])\n",
      "63 torch.Size([1, 3, 32, 224, 224])\n",
      "64 torch.Size([1, 3, 32, 224, 224])\n",
      "65 torch.Size([1, 3, 32, 224, 224])\n",
      "66 torch.Size([1, 3, 32, 224, 224])\n",
      "67 torch.Size([1, 3, 32, 224, 224])\n",
      "68 torch.Size([1, 3, 32, 224, 224])\n",
      "69 torch.Size([1, 3, 32, 224, 224])\n",
      "70 torch.Size([1, 3, 32, 224, 224])\n",
      "71 torch.Size([1, 3, 32, 224, 224])\n",
      "72 torch.Size([1, 3, 32, 224, 224])\n",
      "73 torch.Size([1, 3, 32, 224, 224])\n",
      "74 torch.Size([1, 3, 32, 224, 224])\n",
      "75 torch.Size([1, 3, 32, 224, 224])\n",
      "76 torch.Size([1, 3, 32, 224, 224])\n",
      "77 torch.Size([1, 3, 32, 224, 224])\n",
      "78 torch.Size([1, 3, 32, 224, 224])\n",
      "79 torch.Size([1, 3, 32, 224, 224])\n",
      "80 torch.Size([1, 3, 32, 224, 224])\n",
      "81 torch.Size([1, 3, 32, 224, 224])\n",
      "82 torch.Size([1, 3, 32, 224, 224])\n",
      "83 torch.Size([1, 3, 32, 224, 224])\n",
      "84 torch.Size([1, 3, 32, 224, 224])\n",
      "85 torch.Size([1, 3, 32, 224, 224])\n",
      "86 torch.Size([1, 3, 32, 224, 224])\n",
      "87 torch.Size([1, 3, 32, 224, 224])\n",
      "88 torch.Size([1, 3, 32, 224, 224])\n",
      "89 torch.Size([1, 3, 32, 224, 224])\n",
      "90 torch.Size([1, 3, 32, 224, 224])\n",
      "91 torch.Size([1, 3, 32, 224, 224])\n",
      "92 torch.Size([1, 3, 32, 224, 224])\n",
      "93 torch.Size([1, 3, 32, 224, 224])\n",
      "94 torch.Size([1, 3, 32, 224, 224])\n",
      "95 torch.Size([1, 3, 32, 224, 224])\n",
      "96 torch.Size([1, 3, 32, 224, 224])\n",
      "97 torch.Size([1, 3, 32, 224, 224])\n",
      "98 torch.Size([1, 3, 32, 224, 224])\n",
      "99 torch.Size([1, 3, 32, 224, 224])\n",
      "100 torch.Size([1, 3, 32, 224, 224])\n",
      "101 torch.Size([1, 3, 32, 224, 224])\n",
      "102 torch.Size([1, 3, 32, 224, 224])\n",
      "103 torch.Size([1, 3, 32, 224, 224])\n",
      "104 torch.Size([1, 3, 32, 224, 224])\n",
      "105 torch.Size([1, 3, 32, 224, 224])\n",
      "106 torch.Size([1, 3, 32, 224, 224])\n",
      "107 torch.Size([1, 3, 32, 224, 224])\n",
      "108 torch.Size([1, 3, 32, 224, 224])\n",
      "109 torch.Size([1, 3, 32, 224, 224])\n",
      "110 torch.Size([1, 3, 32, 224, 224])\n",
      "111 torch.Size([1, 3, 32, 224, 224])\n",
      "112 torch.Size([1, 3, 32, 224, 224])\n",
      "113 torch.Size([1, 3, 32, 224, 224])\n",
      "114 torch.Size([1, 3, 32, 224, 224])\n",
      "115 torch.Size([1, 3, 32, 224, 224])\n",
      "116 torch.Size([1, 3, 32, 224, 224])\n",
      "117 torch.Size([1, 3, 32, 224, 224])\n",
      "118 torch.Size([1, 3, 32, 224, 224])\n",
      "119 torch.Size([1, 3, 32, 224, 224])\n",
      "120 torch.Size([1, 3, 32, 224, 224])\n",
      "121 torch.Size([1, 3, 32, 224, 224])\n",
      "122 torch.Size([1, 3, 32, 224, 224])\n",
      "123 torch.Size([1, 3, 32, 224, 224])\n",
      "124 torch.Size([1, 3, 32, 224, 224])\n",
      "125 torch.Size([1, 3, 32, 224, 224])\n",
      "126 torch.Size([1, 3, 32, 224, 224])\n",
      "127 torch.Size([1, 3, 32, 224, 224])\n",
      "128 torch.Size([1, 3, 32, 224, 224])\n",
      "129 torch.Size([1, 3, 32, 224, 224])\n",
      "130 torch.Size([1, 3, 32, 224, 224])\n",
      "131 torch.Size([1, 3, 32, 224, 224])\n",
      "132 torch.Size([1, 3, 32, 224, 224])\n",
      "133 torch.Size([1, 3, 32, 224, 224])\n",
      "134 torch.Size([1, 3, 32, 224, 224])\n",
      "135 torch.Size([1, 3, 32, 224, 224])\n",
      "136 torch.Size([1, 3, 32, 224, 224])\n",
      "137 torch.Size([1, 3, 32, 224, 224])\n",
      "138 torch.Size([1, 3, 32, 224, 224])\n",
      "139 torch.Size([1, 3, 32, 224, 224])\n",
      "140 torch.Size([1, 3, 32, 224, 224])\n",
      "141 torch.Size([1, 3, 32, 224, 224])\n",
      "142 torch.Size([1, 3, 32, 224, 224])\n",
      "143 torch.Size([1, 3, 32, 224, 224])\n",
      "144 torch.Size([1, 3, 32, 224, 224])\n",
      "145 torch.Size([1, 3, 32, 224, 224])\n",
      "146 torch.Size([1, 3, 32, 224, 224])\n",
      "147 torch.Size([1, 3, 32, 224, 224])\n",
      "148 torch.Size([1, 3, 32, 224, 224])\n",
      "149 torch.Size([1, 3, 32, 224, 224])\n",
      "150 torch.Size([1, 3, 32, 224, 224])\n",
      "151 torch.Size([1, 3, 32, 224, 224])\n",
      "152 torch.Size([1, 3, 32, 224, 224])\n",
      "153 torch.Size([1, 3, 32, 224, 224])\n",
      "154 torch.Size([1, 3, 32, 224, 224])\n",
      "155 torch.Size([1, 3, 32, 224, 224])\n",
      "156 torch.Size([1, 3, 32, 224, 224])\n",
      "157 torch.Size([1, 3, 32, 224, 224])\n",
      "158 torch.Size([1, 3, 32, 224, 224])\n",
      "159 torch.Size([1, 3, 32, 224, 224])\n",
      "160 torch.Size([1, 3, 32, 224, 224])\n",
      "161 torch.Size([1, 3, 32, 224, 224])\n",
      "162 torch.Size([1, 3, 32, 224, 224])\n",
      "163 torch.Size([1, 3, 32, 224, 224])\n",
      "164 torch.Size([1, 3, 32, 224, 224])\n",
      "165 torch.Size([1, 3, 32, 224, 224])\n",
      "166 torch.Size([1, 3, 32, 224, 224])\n",
      "167 torch.Size([1, 3, 32, 224, 224])\n",
      "168 torch.Size([1, 3, 32, 224, 224])\n",
      "169 torch.Size([1, 3, 32, 224, 224])\n",
      "170 torch.Size([1, 3, 32, 224, 224])\n",
      "171 torch.Size([1, 3, 32, 224, 224])\n",
      "172 torch.Size([1, 3, 32, 224, 224])\n",
      "173 torch.Size([1, 3, 32, 224, 224])\n",
      "174 torch.Size([1, 3, 32, 224, 224])\n",
      "175 torch.Size([1, 3, 32, 224, 224])\n",
      "176 torch.Size([1, 3, 32, 224, 224])\n",
      "177 torch.Size([1, 3, 32, 224, 224])\n",
      "178 torch.Size([1, 3, 32, 224, 224])\n",
      "179 torch.Size([1, 3, 32, 224, 224])\n",
      "180 torch.Size([1, 3, 32, 224, 224])\n",
      "181 torch.Size([1, 3, 32, 224, 224])\n",
      "182 torch.Size([1, 3, 32, 224, 224])\n",
      "183 torch.Size([1, 3, 32, 224, 224])\n",
      "184 torch.Size([1, 3, 32, 224, 224])\n",
      "185 torch.Size([1, 3, 32, 224, 224])\n",
      "186 torch.Size([1, 3, 32, 224, 224])\n",
      "187 torch.Size([1, 3, 32, 224, 224])\n",
      "188 torch.Size([1, 3, 32, 224, 224])\n",
      "189 torch.Size([1, 3, 32, 224, 224])\n",
      "190 torch.Size([1, 3, 32, 224, 224])\n",
      "191 torch.Size([1, 3, 32, 224, 224])\n",
      "192 torch.Size([1, 3, 32, 224, 224])\n",
      "193 torch.Size([1, 3, 32, 224, 224])\n",
      "194 torch.Size([1, 3, 32, 224, 224])\n",
      "195 torch.Size([1, 3, 32, 224, 224])\n",
      "196 torch.Size([1, 3, 32, 224, 224])\n",
      "197 torch.Size([1, 3, 32, 224, 224])\n",
      "198 torch.Size([1, 3, 32, 224, 224])\n",
      "199 torch.Size([1, 3, 32, 224, 224])\n",
      "200 torch.Size([1, 3, 32, 224, 224])\n",
      "201 torch.Size([1, 3, 32, 224, 224])\n",
      "202 torch.Size([1, 3, 32, 224, 224])\n",
      "203 torch.Size([1, 3, 32, 224, 224])\n",
      "204 torch.Size([1, 3, 32, 224, 224])\n",
      "205 torch.Size([1, 3, 32, 224, 224])\n",
      "206 torch.Size([1, 3, 32, 224, 224])\n",
      "207 torch.Size([1, 3, 32, 224, 224])\n",
      "208 torch.Size([1, 3, 32, 224, 224])\n",
      "209 torch.Size([1, 3, 32, 224, 224])\n",
      "210 torch.Size([1, 3, 32, 224, 224])\n",
      "211 torch.Size([1, 3, 32, 224, 224])\n",
      "212 torch.Size([1, 3, 32, 224, 224])\n",
      "213 torch.Size([1, 3, 32, 224, 224])\n",
      "214 torch.Size([1, 3, 32, 224, 224])\n",
      "215 torch.Size([1, 3, 32, 224, 224])\n",
      "216 torch.Size([1, 3, 32, 224, 224])\n",
      "217 torch.Size([1, 3, 32, 224, 224])\n",
      "218 torch.Size([1, 3, 32, 224, 224])\n",
      "219 torch.Size([1, 3, 32, 224, 224])\n",
      "220 torch.Size([1, 3, 32, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# for num, batch in enumerate(datasets[0]):\n",
    "#     print(num, batch['imgs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa7e7dbf-ff4b-4981-8a8c-55c05d84c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model to test after training, best or last?\n",
    "test_option = dict(test_last=args.test_last, test_best=args.test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ec18ba5-c4f7-46ba-ad56-d574be3b163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2166.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Build the model for \n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cee06-3b44-484b-954b-6fb7558b2705",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35a2c7cb-8783-42b7-9480-f45be536428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "from mmaction.core import DistEvalHook, EvalHook\n",
    "from mmaction.datasets import build_dataloader, build_dataset\n",
    "from mmcv_custom.runner import EpochBasedRunnerAmp\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import DistSamplerSeedHook, EpochBasedRunner, OptimizerHook, build_optimizer, get_dist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10252d76-7ef6-429d-9ae4-a386c33d996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root logger\n",
    "logger = get_root_logger(log_level=cfg.log_level)\n",
    "\n",
    "\n",
    "# Load the data using the GPU\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1) // cfg.optimizer_config.get('update_interval', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    num_gpus=len(cfg.gpu_ids),\n",
    "    dist=distributed,\n",
    "    seed=cfg.seed)\n",
    "\n",
    "# \n",
    "dataloader_setting = dict(dataloader_setting, **cfg.data.get('train_dataloader', {}))\n",
    "data_loaders = [build_dataloader(ds, **dataloader_setting) for ds in datasets]\n",
    "\n",
    "# \n",
    "val_dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    # cfg.gpus will be ignored if distributed\n",
    "    num_gpus=len(cfg.gpu_ids),\n",
    "    dist=distributed,\n",
    "    shuffle=False)\n",
    "\n",
    "dataloader_setting = dict(dataloader_setting, **cfg.data.get('val_dataloader', {}))\n",
    "val_dataloader = build_dataloader(val_dataset, **dataloader_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "759d0fa4-56c1-46ad-a5ad-646407d4607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "# build optimizer\n",
    "optimizer = build_optimizer(model, cfg.optimizer)\n",
    "model, optimizer = apex.amp.initialize(model.cuda(), optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "280c1f8d-1086-4279-8b9f-1d65ad3daadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if hasattr(m, \"fp16_enabled\"):\n",
    "        m.fp16_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d911e1dc-184e-4f32-9730-7861f5d6282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model on GPU's for training\n",
    "if distributed:\n",
    "    find_unused_parameters = cfg.get('find_unused_parameters', False)\n",
    "    # Sets the `find_unused_parameters` parameter in\n",
    "    # torch.nn.parallel.DistributedDataParallel\n",
    "    model = MMDistributedDataParallel(\n",
    "        model.cuda(),\n",
    "        device_ids=[torch.cuda.current_device()],\n",
    "        broadcast_buffers=False,\n",
    "        find_unused_parameters=find_unused_parameters)\n",
    "else:\n",
    "    model = MMDataParallel(\n",
    "        model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f756b41b-ec1a-4f95-88ee-ec56959f4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the class that will run the code \n",
    "Runner = EpochBasedRunnerAmp\n",
    "runner = Runner(model, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta)\n",
    "\n",
    "# an ugly workaround to make .log and .log.json filenames the same\n",
    "runner.timestamp = timestamp\n",
    "\n",
    "# \n",
    "optimizer_config = cfg.optimizer_config\n",
    "\n",
    "# register hooks\n",
    "runner.register_training_hooks(cfg.lr_config, optimizer_config, cfg.checkpoint_config, cfg.log_config, cfg.get('momentum_config', None))\n",
    "\n",
    "if distributed:\n",
    "    runner.register_hook(DistSamplerSeedHook())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "722a52fc-f7f5-4303-99f9-321461dc2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# eval_cfg = cfg.get('evaluation', {})\n",
    "# eval_hook = DistEvalHook if distributed else EvalHook\n",
    "# runner.register_hook(eval_hook(val_dataloader, **eval_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f27dcb4-8d84-4f8a-b711-04e09020986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:14:07,696 - mmaction - INFO - load checkpoint from local path: ../configs/swin_tiny_patch244_window877_kinetics400_1k.pth\n",
      "2022-04-10 21:14:07,837 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 768]) from checkpoint, the shape in current model is torch.Size([5, 768]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([5]).\n"
     ]
    }
   ],
   "source": [
    "if cfg.resume_from:\n",
    "    runner.resume(cfg.resume_from, resume_amp=use_amp)\n",
    "elif cfg.get(\"auto_resume\", False) and osp.exists(osp.join(runner.work_dir, 'latest.pth')):\n",
    "    runner.auto_resume()\n",
    "elif cfg.load_from:\n",
    "    runner.load_checkpoint(cfg.load_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13aeb1d-ccb6-4d8a-8fd0-d9839234182f",
   "metadata": {},
   "source": [
    "## Dashboarding using wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "113ae2f6-b4f6-40cf-b784-02f92c49cbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maswin_thiru\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.14"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Video-Swin-Transformer/wandb/run-20220410_211414-28xpfjfo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aswin_thiru/lamba_bsl/runs/28xpfjfo\" target=\"_blank\">eager-dew-1</a></strong> to <a href=\"https://wandb.ai/aswin_thiru/lamba_bsl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/aswin_thiru/lamba_bsl/runs/28xpfjfo?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f4354e3c1f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=wandb_project_name, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4eebc0db-2f00-465e-9a18-edd56817a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.runner import Hook\n",
    "from torch.utils.data import DataLoader\n",
    "from mmaction.apis import single_gpu_test\n",
    "\n",
    "\n",
    "class WandBHook(Hook):  # noqa: F811\n",
    "    \"\"\"Non-Distributed evaluation hook.\n",
    "\n",
    "    Notes:\n",
    "        If new arguments are added for EvalHook, tools/test.py,\n",
    "        tools/eval_metric.py may be effected.\n",
    "\n",
    "    This hook will regularly perform evaluation in a given interval when\n",
    "    performing in non-distributed environment.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): A PyTorch dataloader.\n",
    "        wandb_obj: A wandb object\n",
    "        optimizer_obj: optimizer object\n",
    "        **eval_kwargs: Evaluation arguments fed into the evaluate function\n",
    "            of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataloader,\n",
    "                 wandb_obj,\n",
    "                 optimizer_obj,\n",
    "                 **eval_kwargs):\n",
    "\n",
    "        if not isinstance(dataloader, DataLoader):\n",
    "            raise TypeError(f'dataloader must be a pytorch DataLoader, '\n",
    "                            f'but got {type(dataloader)}')\n",
    "\n",
    "        self.dataloader = dataloader\n",
    "        self.wandb = wandb\n",
    "        self.eval_kwargs = eval_kwargs\n",
    "    \n",
    "    def before_train_epoch(self, runner):\n",
    "        \"\"\"Called after every train epoch to save learning rate\"\"\"\n",
    "        self.wandb.log({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    def after_val_epoch(self, runner):\n",
    "        \"\"\"Called after every validation epoch to evaluate the results.\"\"\"\n",
    "        self._do_evaluate(runner)\n",
    "\n",
    "    def _do_evaluate(self, runner):\n",
    "        results = single_gpu_test(runner.model, self.dataloader)\n",
    "        eval_res = self.dataloader.dataset.evaluate(results, logger=runner.logger, **self.eval_kwargs)\n",
    "        self.wandb.log(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00329ab1-9f35-4ee8-88cc-0cecd0ac86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.register_hook(WandBHook(val_dataloader, wandb, optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c46dbe0e-bcea-4b42-bbde-4ba6fb18a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:14:19,344 - mmaction - INFO - Start running, host: root@lambda-dual, work_dir: /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py\n",
      "2022-04-10 21:14:19,346 - mmaction - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(NORMAL      ) WandBHook                          \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(NORMAL      ) WandBHook                          \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-04-10 21:14:19,347 - mmaction - INFO - workflow: [('train', 1), ('val', 1)], max: 15 epochs\n",
      "2022-04-10 21:14:19,348 - mmaction - INFO - Checkpoints will be saved to /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py by HardDiskBackend.\n",
      "2022-04-10 21:14:30,613 - mmaction - INFO - Epoch [1][20/111]\tlr: 1.616e-05, eta: 0:15:26, time: 0.563, data_time: 0.154, memory: 2832, top1_acc: 0.1750, top5_acc: 1.0000, loss_cls: 1.6558, loss: 1.6558\n",
      "2022-04-10 21:14:34,771 - mmaction - INFO - Epoch [1][40/111]\tlr: 2.265e-05, eta: 0:10:26, time: 0.208, data_time: 0.001, memory: 2832, top1_acc: 0.2500, top5_acc: 1.0000, loss_cls: 1.6033, loss: 1.6033\n",
      "2022-04-10 21:14:38,889 - mmaction - INFO - Epoch [1][60/111]\tlr: 2.914e-05, eta: 0:08:42, time: 0.206, data_time: 0.001, memory: 2832, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 1.5961, loss: 1.5961\n",
      "2022-04-10 21:14:43,029 - mmaction - INFO - Epoch [1][80/111]\tlr: 3.562e-05, eta: 0:07:49, time: 0.207, data_time: 0.001, memory: 2832, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 1.6036, loss: 1.6036\n",
      "2022-04-10 21:14:47,156 - mmaction - INFO - Epoch [1][100/111]\tlr: 4.211e-05, eta: 0:07:14, time: 0.206, data_time: 0.000, memory: 2832, top1_acc: 0.3750, top5_acc: 1.0000, loss_cls: 1.5799, loss: 1.5799\n",
      "2022-04-10 21:14:49,366 - mmaction - INFO - Saving checkpoint at 1 epochs\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:15:16,948 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:15:16,950 - mmaction - INFO - \n",
      "top1_acc\t0.4000\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:15:16,952 - mmaction - INFO - Epoch(val) [1][28]\ttop1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 1.5185, loss: 1.5185\n",
      "2022-04-10 21:15:24,246 - mmaction - INFO - Epoch [2][20/111]\tlr: 5.159e-05, eta: 0:06:50, time: 0.365, data_time: 0.157, memory: 2833, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 1.5182, loss: 1.5182\n",
      "2022-04-10 21:15:28,388 - mmaction - INFO - Epoch [2][40/111]\tlr: 5.801e-05, eta: 0:06:33, time: 0.207, data_time: 0.001, memory: 2833, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.4292, loss: 1.4292\n",
      "2022-04-10 21:15:32,551 - mmaction - INFO - Epoch [2][60/111]\tlr: 6.442e-05, eta: 0:06:19, time: 0.208, data_time: 0.001, memory: 2835, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 1.3811, loss: 1.3811\n",
      "2022-04-10 21:15:36,670 - mmaction - INFO - Epoch [2][80/111]\tlr: 7.084e-05, eta: 0:06:06, time: 0.206, data_time: 0.001, memory: 2835, top1_acc: 0.4500, top5_acc: 1.0000, loss_cls: 1.3179, loss: 1.3179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:15:40,775 - mmaction - INFO - Epoch [2][100/111]\tlr: 7.725e-05, eta: 0:05:55, time: 0.205, data_time: 0.001, memory: 2835, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 1.2883, loss: 1.2883\n",
      "2022-04-10 21:15:43,041 - mmaction - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 3.1 task/s, elapsed: 18s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:16:09,291 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:16:09,294 - mmaction - INFO - \n",
      "top1_acc\t0.5455\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:16:09,297 - mmaction - INFO - Epoch(val) [2][28]\ttop1_acc: 0.5455, top5_acc: 1.0000, loss_cls: 1.3260, loss: 1.3260\n",
      "2022-04-10 21:16:16,295 - mmaction - INFO - Epoch [3][20/111]\tlr: 8.435e-05, eta: 0:05:44, time: 0.350, data_time: 0.142, memory: 2835, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.2847, loss: 1.2847\n",
      "2022-04-10 21:16:20,451 - mmaction - INFO - Epoch [3][40/111]\tlr: 9.056e-05, eta: 0:05:36, time: 0.208, data_time: 0.001, memory: 2835, top1_acc: 0.5750, top5_acc: 1.0000, loss_cls: 1.1319, loss: 1.1319\n",
      "2022-04-10 21:16:24,636 - mmaction - INFO - Epoch [3][60/111]\tlr: 9.552e-05, eta: 0:05:28, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 1.0240, loss: 1.0240\n",
      "2022-04-10 21:16:28,727 - mmaction - INFO - Epoch [3][80/111]\tlr: 9.552e-05, eta: 0:05:20, time: 0.205, data_time: 0.000, memory: 2835, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.8130, loss: 0.8130\n",
      "2022-04-10 21:16:32,882 - mmaction - INFO - Epoch [3][100/111]\tlr: 9.552e-05, eta: 0:05:13, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.7284, loss: 0.7284\n",
      "2022-04-10 21:16:35,143 - mmaction - INFO - Saving checkpoint at 3 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 3.1 task/s, elapsed: 18s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:17:01,517 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:17:01,518 - mmaction - INFO - \n",
      "top1_acc\t0.7818\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:17:01,520 - mmaction - INFO - Epoch(val) [3][28]\ttop1_acc: 0.7818, top5_acc: 1.0000, loss_cls: 0.5227, loss: 0.5227\n",
      "2022-04-10 21:17:08,505 - mmaction - INFO - Epoch [4][20/111]\tlr: 9.045e-05, eta: 0:05:05, time: 0.349, data_time: 0.138, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4880, loss: 0.4880\n",
      "2022-04-10 21:17:12,659 - mmaction - INFO - Epoch [4][40/111]\tlr: 9.045e-05, eta: 0:04:59, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.5759, loss: 0.5759\n",
      "2022-04-10 21:17:16,803 - mmaction - INFO - Epoch [4][60/111]\tlr: 9.045e-05, eta: 0:04:52, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.7580, loss: 0.7580\n",
      "2022-04-10 21:17:20,978 - mmaction - INFO - Epoch [4][80/111]\tlr: 9.045e-05, eta: 0:04:46, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 0.8076, loss: 0.8076\n",
      "2022-04-10 21:17:25,170 - mmaction - INFO - Epoch [4][100/111]\tlr: 9.045e-05, eta: 0:04:41, time: 0.210, data_time: 0.001, memory: 2835, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.9309, loss: 0.9309\n",
      "2022-04-10 21:17:27,446 - mmaction - INFO - Saving checkpoint at 4 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:17:54,757 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:17:54,759 - mmaction - INFO - \n",
      "top1_acc\t0.7818\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:17:54,763 - mmaction - INFO - Epoch(val) [4][28]\ttop1_acc: 0.7818, top5_acc: 1.0000, loss_cls: 0.6644, loss: 0.6644\n",
      "2022-04-10 21:18:02,096 - mmaction - INFO - Epoch [5][20/111]\tlr: 8.346e-05, eta: 0:04:34, time: 0.366, data_time: 0.159, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.6170, loss: 0.6170\n",
      "2022-04-10 21:18:06,292 - mmaction - INFO - Epoch [5][40/111]\tlr: 8.346e-05, eta: 0:04:29, time: 0.210, data_time: 0.000, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.7637, loss: 0.7637\n",
      "2022-04-10 21:18:10,438 - mmaction - INFO - Epoch [5][60/111]\tlr: 8.346e-05, eta: 0:04:23, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.5043, loss: 0.5043\n",
      "2022-04-10 21:18:14,568 - mmaction - INFO - Epoch [5][80/111]\tlr: 8.346e-05, eta: 0:04:18, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 0.6863, loss: 0.6863\n",
      "2022-04-10 21:18:18,742 - mmaction - INFO - Epoch [5][100/111]\tlr: 8.346e-05, eta: 0:04:13, time: 0.209, data_time: 0.001, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5011, loss: 0.5011\n",
      "2022-04-10 21:18:20,964 - mmaction - INFO - Saving checkpoint at 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:18:48,449 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:18:48,452 - mmaction - INFO - \n",
      "top1_acc\t0.8727\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:18:48,455 - mmaction - INFO - Epoch(val) [5][28]\ttop1_acc: 0.8727, top5_acc: 1.0000, loss_cls: 0.2745, loss: 0.2745\n",
      "2022-04-10 21:18:55,501 - mmaction - INFO - Epoch [6][20/111]\tlr: 7.500e-05, eta: 0:04:06, time: 0.352, data_time: 0.145, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 0.6146, loss: 0.6146\n",
      "2022-04-10 21:18:59,745 - mmaction - INFO - Epoch [6][40/111]\tlr: 7.500e-05, eta: 0:04:01, time: 0.212, data_time: 0.002, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4923, loss: 0.4923\n",
      "2022-04-10 21:19:03,896 - mmaction - INFO - Epoch [6][60/111]\tlr: 7.500e-05, eta: 0:03:56, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4045, loss: 0.4045\n",
      "2022-04-10 21:19:08,067 - mmaction - INFO - Epoch [6][80/111]\tlr: 7.500e-05, eta: 0:03:50, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5358, loss: 0.5358\n",
      "2022-04-10 21:19:12,195 - mmaction - INFO - Epoch [6][100/111]\tlr: 7.500e-05, eta: 0:03:45, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.4640, loss: 0.4640\n",
      "2022-04-10 21:19:14,485 - mmaction - INFO - Saving checkpoint at 6 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 3.0 task/s, elapsed: 18s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:19:40,900 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:19:40,902 - mmaction - INFO - \n",
      "top1_acc\t0.9273\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:19:40,905 - mmaction - INFO - Epoch(val) [6][28]\ttop1_acc: 0.9273, top5_acc: 1.0000, loss_cls: 0.2441, loss: 0.2441\n",
      "2022-04-10 21:19:47,819 - mmaction - INFO - Epoch [7][20/111]\tlr: 6.545e-05, eta: 0:03:38, time: 0.345, data_time: 0.138, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.5269, loss: 0.5269\n",
      "2022-04-10 21:19:52,176 - mmaction - INFO - Epoch [7][40/111]\tlr: 6.545e-05, eta: 0:03:34, time: 0.218, data_time: 0.010, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4552, loss: 0.4552\n",
      "2022-04-10 21:19:56,323 - mmaction - INFO - Epoch [7][60/111]\tlr: 6.545e-05, eta: 0:03:29, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4320, loss: 0.4320\n",
      "2022-04-10 21:20:00,457 - mmaction - INFO - Epoch [7][80/111]\tlr: 6.545e-05, eta: 0:03:24, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4200, loss: 0.4200\n",
      "2022-04-10 21:20:04,590 - mmaction - INFO - Epoch [7][100/111]\tlr: 6.545e-05, eta: 0:03:19, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4867, loss: 0.4867\n",
      "2022-04-10 21:20:06,862 - mmaction - INFO - Saving checkpoint at 7 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:20:34,567 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:20:34,569 - mmaction - INFO - \n",
      "top1_acc\t0.8909\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:20:34,572 - mmaction - INFO - Epoch(val) [7][28]\ttop1_acc: 0.8909, top5_acc: 1.0000, loss_cls: 0.5118, loss: 0.5118\n",
      "2022-04-10 21:20:41,860 - mmaction - INFO - Epoch [8][20/111]\tlr: 5.523e-05, eta: 0:03:13, time: 0.364, data_time: 0.160, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5017, loss: 0.5017\n",
      "2022-04-10 21:20:45,983 - mmaction - INFO - Epoch [8][40/111]\tlr: 5.523e-05, eta: 0:03:08, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3195, loss: 0.3195\n",
      "2022-04-10 21:20:50,127 - mmaction - INFO - Epoch [8][60/111]\tlr: 5.523e-05, eta: 0:03:03, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2970, loss: 0.2970\n",
      "2022-04-10 21:20:54,304 - mmaction - INFO - Epoch [8][80/111]\tlr: 5.523e-05, eta: 0:02:59, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4923, loss: 0.4923\n",
      "2022-04-10 21:20:58,446 - mmaction - INFO - Epoch [8][100/111]\tlr: 5.523e-05, eta: 0:02:54, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4529, loss: 0.4529\n",
      "2022-04-10 21:21:00,726 - mmaction - INFO - Saving checkpoint at 8 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:21:28,438 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:21:28,440 - mmaction - INFO - \n",
      "top1_acc\t0.9273\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:21:28,442 - mmaction - INFO - Epoch(val) [8][28]\ttop1_acc: 0.9273, top5_acc: 1.0000, loss_cls: 0.3802, loss: 0.3802\n",
      "2022-04-10 21:21:35,719 - mmaction - INFO - Epoch [9][20/111]\tlr: 4.477e-05, eta: 0:02:47, time: 0.364, data_time: 0.157, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.4321, loss: 0.4321\n",
      "2022-04-10 21:21:39,864 - mmaction - INFO - Epoch [9][40/111]\tlr: 4.477e-05, eta: 0:02:43, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4293, loss: 0.4293\n",
      "2022-04-10 21:21:43,994 - mmaction - INFO - Epoch [9][60/111]\tlr: 4.477e-05, eta: 0:02:38, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4032, loss: 0.4032\n",
      "2022-04-10 21:21:48,159 - mmaction - INFO - Epoch [9][80/111]\tlr: 4.477e-05, eta: 0:02:33, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2876, loss: 0.2876\n",
      "2022-04-10 21:21:52,278 - mmaction - INFO - Epoch [9][100/111]\tlr: 4.477e-05, eta: 0:02:29, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.4094, loss: 0.4094\n",
      "2022-04-10 21:21:54,511 - mmaction - INFO - Saving checkpoint at 9 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:22:21,819 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:22:21,821 - mmaction - INFO - \n",
      "top1_acc\t0.9091\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:22:21,824 - mmaction - INFO - Epoch(val) [9][28]\ttop1_acc: 0.9091, top5_acc: 1.0000, loss_cls: 0.3821, loss: 0.3821\n",
      "2022-04-10 21:22:29,179 - mmaction - INFO - Epoch [10][20/111]\tlr: 3.455e-05, eta: 0:02:22, time: 0.367, data_time: 0.161, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3768, loss: 0.3768\n",
      "2022-04-10 21:22:33,291 - mmaction - INFO - Epoch [10][40/111]\tlr: 3.455e-05, eta: 0:02:18, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.3701, loss: 0.3701\n",
      "2022-04-10 21:22:37,447 - mmaction - INFO - Epoch [10][60/111]\tlr: 3.455e-05, eta: 0:02:13, time: 0.208, data_time: 0.001, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.1833, loss: 0.1833\n",
      "2022-04-10 21:22:41,615 - mmaction - INFO - Epoch [10][80/111]\tlr: 3.455e-05, eta: 0:02:09, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2839, loss: 0.2839\n",
      "2022-04-10 21:22:45,733 - mmaction - INFO - Epoch [10][100/111]\tlr: 3.455e-05, eta: 0:02:04, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.4213, loss: 0.4213\n",
      "2022-04-10 21:22:47,978 - mmaction - INFO - Saving checkpoint at 10 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:23:15,101 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:23:15,103 - mmaction - INFO - \n",
      "top1_acc\t0.8909\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:23:15,106 - mmaction - INFO - Epoch(val) [10][28]\ttop1_acc: 0.8909, top5_acc: 1.0000, loss_cls: 0.4802, loss: 0.4802\n",
      "2022-04-10 21:23:22,398 - mmaction - INFO - Epoch [11][20/111]\tlr: 2.500e-05, eta: 0:01:57, time: 0.364, data_time: 0.156, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.6193, loss: 0.6193\n",
      "2022-04-10 21:23:26,564 - mmaction - INFO - Epoch [11][40/111]\tlr: 2.500e-05, eta: 0:01:53, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3305, loss: 0.3305\n",
      "2022-04-10 21:23:30,761 - mmaction - INFO - Epoch [11][60/111]\tlr: 2.500e-05, eta: 0:01:48, time: 0.210, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2126, loss: 0.2126\n",
      "2022-04-10 21:23:34,914 - mmaction - INFO - Epoch [11][80/111]\tlr: 2.500e-05, eta: 0:01:44, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4233, loss: 0.4233\n",
      "2022-04-10 21:23:39,088 - mmaction - INFO - Epoch [11][100/111]\tlr: 2.500e-05, eta: 0:01:39, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2087, loss: 0.2087\n",
      "2022-04-10 21:23:41,345 - mmaction - INFO - Saving checkpoint at 11 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:24:09,021 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:24:09,023 - mmaction - INFO - \n",
      "top1_acc\t0.9273\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:24:09,026 - mmaction - INFO - Epoch(val) [11][28]\ttop1_acc: 0.9273, top5_acc: 1.0000, loss_cls: 0.3737, loss: 0.3737\n",
      "2022-04-10 21:24:16,112 - mmaction - INFO - Epoch [12][20/111]\tlr: 1.654e-05, eta: 0:01:33, time: 0.354, data_time: 0.146, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.6251, loss: 0.6251\n",
      "2022-04-10 21:24:20,297 - mmaction - INFO - Epoch [12][40/111]\tlr: 1.654e-05, eta: 0:01:28, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.3684, loss: 0.3684\n",
      "2022-04-10 21:24:24,414 - mmaction - INFO - Epoch [12][60/111]\tlr: 1.654e-05, eta: 0:01:24, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3217, loss: 0.3217\n",
      "2022-04-10 21:24:28,602 - mmaction - INFO - Epoch [12][80/111]\tlr: 1.654e-05, eta: 0:01:19, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5876, loss: 0.5876\n",
      "2022-04-10 21:24:32,797 - mmaction - INFO - Epoch [12][100/111]\tlr: 1.654e-05, eta: 0:01:15, time: 0.210, data_time: 0.000, memory: 2835, top1_acc: 0.9750, top5_acc: 1.0000, loss_cls: 0.2231, loss: 0.2231\n",
      "2022-04-10 21:24:35,034 - mmaction - INFO - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:25:01,977 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:25:01,979 - mmaction - INFO - \n",
      "top1_acc\t0.9455\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:25:01,982 - mmaction - INFO - Epoch(val) [12][28]\ttop1_acc: 0.9455, top5_acc: 1.0000, loss_cls: 0.3105, loss: 0.3105\n",
      "2022-04-10 21:25:08,957 - mmaction - INFO - Epoch [13][20/111]\tlr: 9.549e-06, eta: 0:01:08, time: 0.348, data_time: 0.140, memory: 2835, top1_acc: 0.9750, top5_acc: 1.0000, loss_cls: 0.1378, loss: 0.1378\n",
      "2022-04-10 21:25:13,076 - mmaction - INFO - Epoch [13][40/111]\tlr: 9.549e-06, eta: 0:01:04, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4209, loss: 0.4209\n",
      "2022-04-10 21:25:17,261 - mmaction - INFO - Epoch [13][60/111]\tlr: 9.549e-06, eta: 0:00:59, time: 0.209, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3000, loss: 0.3000\n",
      "2022-04-10 21:25:21,417 - mmaction - INFO - Epoch [13][80/111]\tlr: 9.549e-06, eta: 0:00:55, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.1806, loss: 0.1806\n",
      "2022-04-10 21:25:25,577 - mmaction - INFO - Epoch [13][100/111]\tlr: 9.549e-06, eta: 0:00:50, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.1805, loss: 0.1805\n",
      "2022-04-10 21:25:27,824 - mmaction - INFO - Saving checkpoint at 13 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 3.0 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:25:54,944 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:25:54,946 - mmaction - INFO - \n",
      "top1_acc\t0.9455\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:25:54,950 - mmaction - INFO - Epoch(val) [13][28]\ttop1_acc: 0.9455, top5_acc: 1.0000, loss_cls: 0.4076, loss: 0.4076\n",
      "2022-04-10 21:26:02,156 - mmaction - INFO - Epoch [14][20/111]\tlr: 4.323e-06, eta: 0:00:44, time: 0.360, data_time: 0.153, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2476, loss: 0.2476\n",
      "2022-04-10 21:26:06,427 - mmaction - INFO - Epoch [14][40/111]\tlr: 4.323e-06, eta: 0:00:39, time: 0.214, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2249, loss: 0.2249\n",
      "2022-04-10 21:26:10,579 - mmaction - INFO - Epoch [14][60/111]\tlr: 4.323e-06, eta: 0:00:35, time: 0.208, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2535, loss: 0.2535\n",
      "2022-04-10 21:26:14,693 - mmaction - INFO - Epoch [14][80/111]\tlr: 4.323e-06, eta: 0:00:31, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4378, loss: 0.4378\n",
      "2022-04-10 21:26:18,838 - mmaction - INFO - Epoch [14][100/111]\tlr: 4.323e-06, eta: 0:00:26, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2988, loss: 0.2988\n",
      "2022-04-10 21:26:21,137 - mmaction - INFO - Saving checkpoint at 14 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:26:48,264 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:26:48,267 - mmaction - INFO - \n",
      "top1_acc\t0.9455\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:26:48,270 - mmaction - INFO - Epoch(val) [14][28]\ttop1_acc: 0.9455, top5_acc: 1.0000, loss_cls: 0.3429, loss: 0.3429\n",
      "2022-04-10 21:26:55,502 - mmaction - INFO - Epoch [15][20/111]\tlr: 1.093e-06, eta: 0:00:19, time: 0.361, data_time: 0.156, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.1869, loss: 0.1869\n",
      "2022-04-10 21:26:59,838 - mmaction - INFO - Epoch [15][40/111]\tlr: 1.093e-06, eta: 0:00:15, time: 0.217, data_time: 0.008, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.1922, loss: 0.1922\n",
      "2022-04-10 21:27:04,046 - mmaction - INFO - Epoch [15][60/111]\tlr: 1.093e-06, eta: 0:00:11, time: 0.210, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2450, loss: 0.2450\n",
      "2022-04-10 21:27:08,156 - mmaction - INFO - Epoch [15][80/111]\tlr: 1.093e-06, eta: 0:00:06, time: 0.206, data_time: 0.000, memory: 2835, top1_acc: 0.9750, top5_acc: 1.0000, loss_cls: 0.1844, loss: 0.1844\n",
      "2022-04-10 21:27:12,291 - mmaction - INFO - Epoch [15][100/111]\tlr: 1.093e-06, eta: 0:00:02, time: 0.207, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2689, loss: 0.2689\n",
      "2022-04-10 21:27:14,537 - mmaction - INFO - Saving checkpoint at 15 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-10 21:27:41,854 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-10 21:27:41,856 - mmaction - INFO - \n",
      "top1_acc\t0.9455\n",
      "top5_acc\t1.0000\n",
      "2022-04-10 21:27:41,860 - mmaction - INFO - Epoch(val) [15][28]\ttop1_acc: 0.9455, top5_acc: 1.0000, loss_cls: 0.3426, loss: 0.3426\n"
     ]
    }
   ],
   "source": [
    "runner_kwargs = dict()\n",
    "runner.run(data_loaders, cfg.workflow, cfg.total_epochs, **runner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8da66c68-4b16-4ffb-b79f-1847e3355d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>███▇▇▆▆▅▄▃▃▂▂▁▁</td></tr><tr><td>top1_acc</td><td>▁▃▆▆▇█▇██▇█████</td></tr><tr><td>top5_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0</td></tr><tr><td>top1_acc</td><td>0.94545</td></tr><tr><td>top5_acc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">eager-dew-1</strong>: <a href=\"https://wandb.ai/aswin_thiru/lamba_bsl/runs/28xpfjfo\" target=\"_blank\">https://wandb.ai/aswin_thiru/lamba_bsl/runs/28xpfjfo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220410_211414-28xpfjfo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343d7a4-fcbb-482d-8002-f9233fba7510",
   "metadata": {},
   "source": [
    "## Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52e95cd6-16cc-4bbd-94df-8a9dd18b6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # init distributed env first, since logger depends on the dist info.\n",
    "# if args.launcher == 'none':\n",
    "#     distributed = False\n",
    "# else:\n",
    "#     distributed = True\n",
    "#     init_dist(args.launcher, **cfg.dist_params)\n",
    "#     _, world_size = get_dist_info()\n",
    "#     cfg.gpu_ids = range(world_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
