{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a7aed7-6b2a-4081-8ed3-7847c97ac7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../Video-Swin-Transformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5c1440-6b87-41d0-814a-b275108a97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change teh working directory to a location that the code prefers\n",
    "os.chdir(\"../Video-Swin-Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e4a28c-4e43-4cde-8e9a-3d7236acb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist, set_random_seed\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmaction import __version__\n",
    "from mmaction.apis import train_model\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.utils import collect_env, get_root_logger, register_module_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea8e512-db21-4cb2-9101-305199748aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c521d7ba-77f0-4cc9-8dd2-9a426f07b409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maswin_thiru\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Log in to your W&B account\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824ca902-3e0b-48f7-8bd2-57db303a9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project_name = 'bsl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "befe8d30-137b-48ee-8fff-5f6c81f50d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import test functions from mmcv and delete them from mmaction2\n",
    "try:\n",
    "    from mmcv.engine import multi_gpu_test, single_gpu_test\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    warnings.warn(\n",
    "        'DeprecationWarning: single_gpu_test, multi_gpu_test, '\n",
    "        'collect_results_cpu, collect_results_gpu from mmaction2 will be '\n",
    "        'deprecated. Please install mmcv through master branch.')\n",
    "    from mmaction.apis import multi_gpu_test, single_gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "790667cc-bad1-43c0-9df4-a7e86c65dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(parse_options=None):\n",
    "    parser = argparse.ArgumentParser(description='Train a recognizer')\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    parser.add_argument(\n",
    "        '--load-from', help='the checkpoint file to load from')\n",
    "    parser.add_argument(\n",
    "        '--validate',\n",
    "        action='store_true',\n",
    "        help='whether to evaluate the checkpoint during training')\n",
    "    parser.add_argument(\n",
    "        '--test-last',\n",
    "        action='store_true',\n",
    "        help='whether to test the checkpoint after training')\n",
    "    parser.add_argument(\n",
    "        '--test-best',\n",
    "        action='store_true',\n",
    "        help=('whether to test the best checkpoint (if applicable) after '\n",
    "              'training'))\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        default={},\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. For example, '\n",
    "        \"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\")\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    \n",
    "    if parse_options is None: \n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(parse_options)\n",
    "        \n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5baa4b97-74b5-4082-9a12-3cf378f11bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the cofiguration and data file\n",
    "config_file = '../configs/bsl_config.py'\n",
    "check_point_file = '../configs/swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
    "# , \"model.backbone.pretrained=\"+check_point_file\n",
    "# cmd_options = [config_file, \"--cfg-options\", \"model.backbone.use_checkpoint=True\", \"--load-from\", check_point_file,\n",
    "#                \"--seed\", \"12345\"]\n",
    "cmd_options = [config_file, \"--cfg-options\", \"model.backbone.use_checkpoint=True\", \"--load-from\", check_point_file,\n",
    "              \"--validate\", \"--seed\", \"12345\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdd078b-640c-4500-bfb6-737ccde06ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e35d5ede-d413-405f-9fce-5be60ba5183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py\n",
      "../Video-Swin-Transformer/configs/_base_/default_runtime.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:44:10,796 - mmaction - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]\n",
      "CUDA available: True\n",
      "GPU 0: Tesla T4\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Build cuda_11.6.r11.6/compiler.30794723_0\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n",
      "PyTorch: 1.11.0a0+17540c5\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.3.3 (Git Hash N/A)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_86,code=compute_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS=-fno-gnu-unique -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0a0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.4.0\n",
      "MMCV Compiler: GCC 9.3\n",
      "MMCV CUDA Compiler: not available\n",
      "MMAction2: 0.15.0+db018fb\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-03-23 22:44:10,797 - mmaction - INFO - Distributed training: False\n",
      "2022-03-23 22:44:11,025 - mmaction - INFO - Config: model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer3D',\n",
      "        patch_size=(2, 4, 4),\n",
      "        embed_dim=96,\n",
      "        depths=[2, 2, 6, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        window_size=(8, 7, 7),\n",
      "        mlp_ratio=4.0,\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        patch_norm=True,\n",
      "        use_checkpoint=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        in_channels=768,\n",
      "        num_classes=5,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5),\n",
      "    test_cfg=dict(average_clips='prob', max_testing_views=4))\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '../configs/swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1), ('val', 1)]\n",
      "swin_tiny_path = '../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py'\n",
      "runtime_path = '../Video-Swin-Transformer/configs/_base_/default_runtime.py'\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = '../processed_videos'\n",
      "data_root_train = '../processed_videos/train'\n",
      "data_root_val = '../processed_videos/val'\n",
      "ann_file_train = '../processed_videos/bsl_train_video.txt'\n",
      "ann_file_val = '../processed_videos/bsl_val_video.txt'\n",
      "ann_file_test = '../processed_videos/bsl_val_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 224)),\n",
      "    dict(type='ThreeCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    val_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    test_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_train_video.txt',\n",
      "        data_prefix='../processed_videos/train',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_val_video.txt',\n",
      "        data_prefix='../processed_videos/val',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_val_video.txt',\n",
      "        data_prefix='../processed_videos/val',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 224)),\n",
      "            dict(type='ThreeCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.001,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.02,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            backbone=dict(lr_mult=0.1))))\n",
      "lr_config = dict(\n",
      "    policy='CosineAnnealing',\n",
      "    min_lr=0,\n",
      "    warmup='linear',\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=2.5)\n",
      "total_epochs = 30\n",
      "work_dir = './work_dirs/k400_swin_tiny_patch244_window877.py'\n",
      "find_unused_parameters = False\n",
      "fp16 = None\n",
      "optimizer_config = dict(\n",
      "    type='DistOptimizerHook',\n",
      "    update_interval=4,\n",
      "    grad_clip=None,\n",
      "    coalesce=True,\n",
      "    bucket_size_mb=-1,\n",
      "    use_fp16=True)\n",
      "gpu_ids = range(0, 1)\n",
      "omnisource = False\n",
      "module_hooks = []\n",
      "\n",
      "2022-03-23 22:44:11,026 - mmaction - INFO - Set random seed to 12345, deterministic: False\n"
     ]
    }
   ],
   "source": [
    "# Create a configuration object that describes the training and testing\n",
    "args = parse_args(cmd_options)\n",
    "cfg = Config.fromfile(args.config)\n",
    "cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "# Customization for training the BSL data set\n",
    "# https://mmcv.readthedocs.io/en/latest/_modules/mmcv/runner/epoch_based_runner.html\n",
    "cfg.workflow = [('train', 1), ('val', 1)]\n",
    "# cfg.workflow = [('train', 1), ]\n",
    "cfg.model.cls_head.num_classes = 5\n",
    "\n",
    "# Resume from this pyhton checkpoint file\n",
    "cfg.resume_from = args.resume_from\n",
    "cfg.load_from = args.load_from\n",
    "\n",
    "# One GPU\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "# Omnisource reference: https://arxiv.org/abs/2003.13042\n",
    "cfg.setdefault('omnisource', False)\n",
    "\n",
    "# The flag is used to register module's hooks\n",
    "cfg.setdefault('module_hooks', [])\n",
    "\n",
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# dump config\n",
    "cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))\n",
    "\n",
    "# init logger before other steps\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "# init the meta dict to record some important information such as\n",
    "# environment info and seed, which will be logged\n",
    "meta = dict()\n",
    "# log env info\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([f'{k}: {v}' for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "            dash_line)\n",
    "meta['env_info'] = env_info\n",
    "\n",
    "# log some basic info\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config: {cfg.pretty_text}')\n",
    "\n",
    "# Set seed for training\n",
    "logger.info(f'Set random seed to {args.seed}, '\n",
    "            f'deterministic: {args.deterministic}')\n",
    "set_random_seed(args.seed, deterministic=args.deterministic)\n",
    "\n",
    "cfg.seed = args.seed\n",
    "meta['seed'] = args.seed\n",
    "meta['config_name'] = osp.basename(args.config)\n",
    "meta['work_dir'] = osp.basename(cfg.work_dir.rstrip('/\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f965ec0-5475-4d9e-8680-1750367df750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Validation is setup as a hook that kicks off every 5 iterations\n",
    "# This is not required\n",
    "if 1:\n",
    "    # Create the validation dataset\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    datasets.append(build_dataset(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78afc72a-490e-4cf5-ab6d-1af0f142038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa7e7dbf-ff4b-4981-8a8c-55c05d84c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model to test after training, best or last?\n",
    "test_option = dict(test_last=args.test_last, test_best=args.test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec18ba5-c4f7-46ba-ad56-d574be3b163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2166.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Build the model for \n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cee06-3b44-484b-954b-6fb7558b2705",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a2c7cb-8783-42b7-9480-f45be536428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "from mmaction.core import DistEvalHook, EvalHook\n",
    "from mmaction.datasets import build_dataloader, build_dataset\n",
    "from mmcv_custom.runner import EpochBasedRunnerAmp\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import DistSamplerSeedHook, EpochBasedRunner, OptimizerHook, build_optimizer, get_dist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10252d76-7ef6-429d-9ae4-a386c33d996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root logger\n",
    "logger = get_root_logger(log_level=cfg.log_level)\n",
    "\n",
    "\n",
    "# Load the data using the GPU\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1) // cfg.optimizer_config.get('update_interval', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    num_gpus=len(cfg.gpu_ids),\n",
    "    dist=distributed,\n",
    "    seed=cfg.seed)\n",
    "\n",
    "# \n",
    "dataloader_setting = dict(dataloader_setting, **cfg.data.get('train_dataloader', {}))\n",
    "data_loaders = [build_dataloader(ds, **dataloader_setting) for ds in datasets]\n",
    "\n",
    "# \n",
    "val_dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    # cfg.gpus will be ignored if distributed\n",
    "    num_gpus=len(cfg.gpu_ids),\n",
    "    dist=distributed,\n",
    "    shuffle=False)\n",
    "\n",
    "dataloader_setting = dict(dataloader_setting, **cfg.data.get('val_dataloader', {}))\n",
    "val_dataloader = build_dataloader(val_dataset, **dataloader_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "759d0fa4-56c1-46ad-a5ad-646407d4607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "# build optimizer\n",
    "optimizer = build_optimizer(model, cfg.optimizer)\n",
    "model, optimizer = apex.amp.initialize(model.cuda(), optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "280c1f8d-1086-4279-8b9f-1d65ad3daadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if hasattr(m, \"fp16_enabled\"):\n",
    "        m.fp16_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d911e1dc-184e-4f32-9730-7861f5d6282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model on GPU's for training\n",
    "if distributed:\n",
    "    find_unused_parameters = cfg.get('find_unused_parameters', False)\n",
    "    # Sets the `find_unused_parameters` parameter in\n",
    "    # torch.nn.parallel.DistributedDataParallel\n",
    "    model = MMDistributedDataParallel(\n",
    "        model.cuda(),\n",
    "        device_ids=[torch.cuda.current_device()],\n",
    "        broadcast_buffers=False,\n",
    "        find_unused_parameters=find_unused_parameters)\n",
    "else:\n",
    "    model = MMDataParallel(\n",
    "        model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f756b41b-ec1a-4f95-88ee-ec56959f4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the class that will run the code \n",
    "Runner = EpochBasedRunnerAmp\n",
    "runner = Runner(model, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta)\n",
    "\n",
    "# an ugly workaround to make .log and .log.json filenames the same\n",
    "runner.timestamp = timestamp\n",
    "\n",
    "# \n",
    "optimizer_config = cfg.optimizer_config\n",
    "\n",
    "# register hooks\n",
    "runner.register_training_hooks(cfg.lr_config, optimizer_config, cfg.checkpoint_config, cfg.log_config, cfg.get('momentum_config', None))\n",
    "\n",
    "if distributed:\n",
    "    runner.register_hook(DistSamplerSeedHook())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "722a52fc-f7f5-4303-99f9-321461dc2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "eval_cfg = cfg.get('evaluation', {})\n",
    "eval_hook = DistEvalHook if distributed else EvalHook\n",
    "runner.register_hook(eval_hook(val_dataloader, **eval_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f27dcb4-8d84-4f8a-b711-04e09020986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:44:13,310 - mmaction - INFO - load checkpoint from local path: ../configs/swin_tiny_patch244_window877_kinetics400_1k.pth\n",
      "2022-03-23 22:44:13,418 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 768]) from checkpoint, the shape in current model is torch.Size([5, 768]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([5]).\n"
     ]
    }
   ],
   "source": [
    "if cfg.resume_from:\n",
    "    runner.resume(cfg.resume_from, resume_amp=use_amp)\n",
    "elif cfg.get(\"auto_resume\", False) and osp.exists(osp.join(runner.work_dir, 'latest.pth')):\n",
    "    runner.auto_resume()\n",
    "elif cfg.load_from:\n",
    "    runner.load_checkpoint(cfg.load_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13aeb1d-ccb6-4d8a-8fd0-d9839234182f",
   "metadata": {},
   "source": [
    "## Dashboarding using wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "113ae2f6-b4f6-40cf-b784-02f92c49cbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Video-Swin-Transformer/wandb/run-20220323_224413-8lr42xs6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aswin_thiru/bsl/runs/8lr42xs6\" target=\"_blank\">faithful-brook-3</a></strong> to <a href=\"https://wandb.ai/aswin_thiru/bsl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/aswin_thiru/bsl/runs/8lr42xs6?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7feed6a6f6a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=wandb_project_name, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eebc0db-2f00-465e-9a18-edd56817a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.runner import Hook\n",
    "from torch.utils.data import DataLoader\n",
    "from mmaction.apis import single_gpu_test\n",
    "\n",
    "\n",
    "class WandBHook(Hook):  # noqa: F811\n",
    "    \"\"\"Non-Distributed evaluation hook.\n",
    "\n",
    "    Notes:\n",
    "        If new arguments are added for EvalHook, tools/test.py,\n",
    "        tools/eval_metric.py may be effected.\n",
    "\n",
    "    This hook will regularly perform evaluation in a given interval when\n",
    "    performing in non-distributed environment.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): A PyTorch dataloader.\n",
    "        wandb_obj: A wandb object\n",
    "        optimizer_obj: optimizer object\n",
    "        **eval_kwargs: Evaluation arguments fed into the evaluate function\n",
    "            of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataloader,\n",
    "                 wandb_obj,\n",
    "                 optimizer_obj,\n",
    "                 **eval_kwargs):\n",
    "\n",
    "        if not isinstance(dataloader, DataLoader):\n",
    "            raise TypeError(f'dataloader must be a pytorch DataLoader, '\n",
    "                            f'but got {type(dataloader)}')\n",
    "\n",
    "        self.dataloader = dataloader\n",
    "        self.wandb = wandb\n",
    "        self.eval_kwargs = eval_kwargs\n",
    "    \n",
    "    def before_train_epoch(self, runner):\n",
    "        \"\"\"Called after every train epoch to save learning rate\"\"\"\n",
    "        self.wandb.log({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    def after_val_epoch(self, runner):\n",
    "        \"\"\"Called after every validation epoch to evaluate the results.\"\"\"\n",
    "        self._do_evaluate(runner)\n",
    "\n",
    "    def _do_evaluate(self, runner):\n",
    "        results = single_gpu_test(runner.model, self.dataloader)\n",
    "        eval_res = self.dataloader.dataset.evaluate(results, logger=runner.logger, **self.eval_kwargs)\n",
    "        self.wandb.log(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00329ab1-9f35-4ee8-88cc-0cecd0ac86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.register_hook(WandBHook(val_dataloader, wandb, optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c46dbe0e-bcea-4b42-bbde-4ba6fb18a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:44:15,147 - mmaction - INFO - Start running, host: root@ip-10-0-0-32, work_dir: /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py\n",
      "2022-03-23 22:44:15,148 - mmaction - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(NORMAL      ) EvalHook                           \n",
      "(NORMAL      ) WandBHook                          \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(NORMAL      ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(NORMAL      ) WandBHook                          \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-03-23 22:44:15,149 - mmaction - INFO - workflow: [('train', 1), ('val', 1)], max: 30 epochs\n",
      "2022-03-23 22:44:15,150 - mmaction - INFO - Checkpoints will be saved to /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py by HardDiskBackend.\n",
      "2022-03-23 22:44:33,790 - mmaction - INFO - Epoch [1][20/109]\tlr: 1.628e-05, eta: 0:50:28, time: 0.932, data_time: 0.165, memory: 2832, top1_acc: 0.2250, top5_acc: 1.0000, loss_cls: 1.6020, loss: 1.6020\n",
      "2022-03-23 22:44:46,835 - mmaction - INFO - Epoch [1][40/109]\tlr: 2.288e-05, eta: 0:42:38, time: 0.652, data_time: 0.001, memory: 2832, top1_acc: 0.1750, top5_acc: 1.0000, loss_cls: 1.6252, loss: 1.6252\n",
      "2022-03-23 22:44:59,910 - mmaction - INFO - Epoch [1][60/109]\tlr: 2.949e-05, eta: 0:39:54, time: 0.654, data_time: 0.001, memory: 2832, top1_acc: 0.2750, top5_acc: 1.0000, loss_cls: 1.5821, loss: 1.5821\n",
      "2022-03-23 22:45:13,038 - mmaction - INFO - Epoch [1][80/109]\tlr: 3.609e-05, eta: 0:38:28, time: 0.656, data_time: 0.001, memory: 2832, top1_acc: 0.2250, top5_acc: 1.0000, loss_cls: 1.5835, loss: 1.5835\n",
      "2022-03-23 22:45:26,184 - mmaction - INFO - Epoch [1][100/109]\tlr: 4.270e-05, eta: 0:37:31, time: 0.657, data_time: 0.001, memory: 2832, top1_acc: 0.3500, top5_acc: 1.0000, loss_cls: 1.5816, loss: 1.5816\n",
      "2022-03-23 22:45:31,831 - mmaction - INFO - Saving checkpoint at 1 epochs\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:46:24,816 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 22:46:24,818 - mmaction - INFO - \n",
      "top1_acc\t0.3390\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 22:46:24,820 - mmaction - INFO - Epoch(val) [1][30]\ttop1_acc: 0.3390, top5_acc: 1.0000, loss_cls: 1.5369, loss: 1.5369\n",
      "2022-03-23 22:46:41,535 - mmaction - INFO - Epoch [2][20/109]\tlr: 5.213e-05, eta: 0:35:36, time: 0.836, data_time: 0.174, memory: 2832, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.4515, loss: 1.4515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:46:54,721 - mmaction - INFO - Epoch [2][40/109]\tlr: 5.872e-05, eta: 0:35:14, time: 0.659, data_time: 0.001, memory: 2833, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.3718, loss: 1.3718\n",
      "2022-03-23 22:47:07,965 - mmaction - INFO - Epoch [2][60/109]\tlr: 6.531e-05, eta: 0:34:54, time: 0.662, data_time: 0.001, memory: 2833, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.3100, loss: 1.3100\n",
      "2022-03-23 22:47:21,255 - mmaction - INFO - Epoch [2][80/109]\tlr: 7.189e-05, eta: 0:34:37, time: 0.664, data_time: 0.001, memory: 2833, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.2520, loss: 1.2520\n",
      "2022-03-23 22:47:34,569 - mmaction - INFO - Epoch [2][100/109]\tlr: 7.848e-05, eta: 0:34:21, time: 0.666, data_time: 0.001, memory: 2833, top1_acc: 0.4500, top5_acc: 1.0000, loss_cls: 1.2875, loss: 1.2875\n",
      "2022-03-23 22:47:40,322 - mmaction - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:48:35,115 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 22:48:35,116 - mmaction - INFO - \n",
      "top1_acc\t0.6949\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 22:48:35,118 - mmaction - INFO - Epoch(val) [2][30]\ttop1_acc: 0.6949, top5_acc: 1.0000, loss_cls: 0.8413, loss: 0.8413\n",
      "2022-03-23 22:48:52,277 - mmaction - INFO - Epoch [3][20/109]\tlr: 8.731e-05, eta: 0:33:31, time: 0.858, data_time: 0.193, memory: 2833, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.8277, loss: 0.8277\n",
      "2022-03-23 22:49:05,539 - mmaction - INFO - Epoch [3][40/109]\tlr: 9.384e-05, eta: 0:33:18, time: 0.663, data_time: 0.001, memory: 2835, top1_acc: 0.6250, top5_acc: 1.0000, loss_cls: 1.0233, loss: 1.0233\n",
      "2022-03-23 22:49:18,825 - mmaction - INFO - Epoch [3][60/109]\tlr: 9.874e-05, eta: 0:33:05, time: 0.664, data_time: 0.001, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 0.8775, loss: 0.8775\n",
      "2022-03-23 22:49:32,121 - mmaction - INFO - Epoch [3][80/109]\tlr: 9.874e-05, eta: 0:32:52, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 0.8396, loss: 0.8396\n",
      "2022-03-23 22:49:45,430 - mmaction - INFO - Epoch [3][100/109]\tlr: 9.874e-05, eta: 0:32:39, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.5000, top5_acc: 1.0000, loss_cls: 1.2563, loss: 1.2563\n",
      "2022-03-23 22:49:51,171 - mmaction - INFO - Saving checkpoint at 3 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:50:44,624 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 22:50:44,625 - mmaction - INFO - \n",
      "top1_acc\t0.5424\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 22:50:44,627 - mmaction - INFO - Epoch(val) [3][30]\ttop1_acc: 0.5424, top5_acc: 1.0000, loss_cls: 0.9605, loss: 0.9605\n",
      "2022-03-23 22:51:02,111 - mmaction - INFO - Epoch [4][20/109]\tlr: 9.755e-05, eta: 0:32:05, time: 0.874, data_time: 0.211, memory: 2835, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.0704, loss: 1.0704\n",
      "2022-03-23 22:51:15,372 - mmaction - INFO - Epoch [4][40/109]\tlr: 9.755e-05, eta: 0:31:52, time: 0.663, data_time: 0.000, memory: 2835, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.9004, loss: 0.9004\n",
      "2022-03-23 22:51:28,662 - mmaction - INFO - Epoch [4][60/109]\tlr: 9.755e-05, eta: 0:31:40, time: 0.664, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.6199, loss: 0.6199\n",
      "2022-03-23 22:51:41,971 - mmaction - INFO - Epoch [4][80/109]\tlr: 9.755e-05, eta: 0:31:28, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.6500, top5_acc: 1.0000, loss_cls: 0.7742, loss: 0.7742\n",
      "2022-03-23 22:51:55,338 - mmaction - INFO - Epoch [4][100/109]\tlr: 9.755e-05, eta: 0:31:16, time: 0.668, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.6360, loss: 0.6360\n",
      "2022-03-23 22:52:01,094 - mmaction - INFO - Saving checkpoint at 4 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:52:53,914 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 22:52:53,915 - mmaction - INFO - \n",
      "top1_acc\t0.7627\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 22:52:53,917 - mmaction - INFO - Epoch(val) [4][30]\ttop1_acc: 0.7627, top5_acc: 1.0000, loss_cls: 0.4756, loss: 0.4756\n",
      "2022-03-23 22:53:11,701 - mmaction - INFO - Epoch [5][20/109]\tlr: 9.568e-05, eta: 0:30:48, time: 0.889, data_time: 0.225, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.6702, loss: 0.6702\n",
      "2022-03-23 22:53:24,977 - mmaction - INFO - Epoch [5][40/109]\tlr: 9.568e-05, eta: 0:30:36, time: 0.664, data_time: 0.001, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 0.9032, loss: 0.9032\n",
      "2022-03-23 22:53:38,273 - mmaction - INFO - Epoch [5][60/109]\tlr: 9.568e-05, eta: 0:30:24, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.3957, loss: 0.3957\n",
      "2022-03-23 22:53:51,594 - mmaction - INFO - Epoch [5][80/109]\tlr: 9.568e-05, eta: 0:30:11, time: 0.666, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.6458, loss: 0.6458\n",
      "2022-03-23 22:54:04,942 - mmaction - INFO - Epoch [5][100/109]\tlr: 9.568e-05, eta: 0:29:59, time: 0.667, data_time: 0.000, memory: 2835, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.6956, loss: 0.6956\n",
      "2022-03-23 22:54:10,688 - mmaction - INFO - Saving checkpoint at 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:54:49,059 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 22:54:49,061 - mmaction - INFO - \n",
      "top1_acc\t0.8305\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 22:54:49,061 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2022-03-23 22:54:49,062 - mmaction - INFO - \n",
      "mean_acc\t0.8462\n",
      "2022-03-23 22:54:50,079 - mmaction - INFO - Now best checkpoint is saved as best_top1_acc_epoch_5.pth.\n",
      "2022-03-23 22:54:50,080 - mmaction - INFO - Best top1_acc is 0.8305 at 5 epoch.\n",
      "2022-03-23 22:54:50,080 - mmaction - INFO - Epoch(val) [5][59]\ttop1_acc: 0.8305, top5_acc: 1.0000, mean_class_accuracy: 0.8462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:55:41,899 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 22:55:41,900 - mmaction - INFO - \n",
      "top1_acc\t0.8305\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 22:55:41,903 - mmaction - INFO - Epoch(val) [5][30]\ttop1_acc: 0.8305, top5_acc: 1.0000, loss_cls: 0.4029, loss: 0.4029\n",
      "2022-03-23 22:55:58,564 - mmaction - INFO - Epoch [6][20/109]\tlr: 9.330e-05, eta: 0:29:28, time: 0.833, data_time: 0.170, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.7197, loss: 0.7197\n",
      "2022-03-23 22:56:11,798 - mmaction - INFO - Epoch [6][40/109]\tlr: 9.330e-05, eta: 0:29:16, time: 0.662, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.5926, loss: 0.5926\n",
      "2022-03-23 22:56:25,073 - mmaction - INFO - Epoch [6][60/109]\tlr: 9.330e-05, eta: 0:29:04, time: 0.664, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5243, loss: 0.5243\n",
      "2022-03-23 22:56:38,374 - mmaction - INFO - Epoch [6][80/109]\tlr: 9.330e-05, eta: 0:28:52, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.2810, loss: 0.2810\n",
      "2022-03-23 22:56:51,691 - mmaction - INFO - Epoch [6][100/109]\tlr: 9.330e-05, eta: 0:28:39, time: 0.666, data_time: 0.001, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.5365, loss: 0.5365\n",
      "2022-03-23 22:56:57,418 - mmaction - INFO - Saving checkpoint at 6 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 22:57:50,300 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 22:57:50,301 - mmaction - INFO - \n",
      "top1_acc\t0.8136\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 22:57:50,303 - mmaction - INFO - Epoch(val) [6][30]\ttop1_acc: 0.8136, top5_acc: 1.0000, loss_cls: 0.4516, loss: 0.4516\n",
      "2022-03-23 22:58:07,628 - mmaction - INFO - Epoch [7][20/109]\tlr: 9.045e-05, eta: 0:28:14, time: 0.866, data_time: 0.203, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4370, loss: 0.4370\n",
      "2022-03-23 22:58:20,905 - mmaction - INFO - Epoch [7][40/109]\tlr: 9.045e-05, eta: 0:28:02, time: 0.664, data_time: 0.001, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2992, loss: 0.2992\n",
      "2022-03-23 22:58:34,196 - mmaction - INFO - Epoch [7][60/109]\tlr: 9.045e-05, eta: 0:27:49, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3754, loss: 0.3754\n",
      "2022-03-23 22:58:47,497 - mmaction - INFO - Epoch [7][80/109]\tlr: 9.045e-05, eta: 0:27:37, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.3887, loss: 0.3887\n",
      "2022-03-23 22:59:00,825 - mmaction - INFO - Epoch [7][100/109]\tlr: 9.045e-05, eta: 0:27:25, time: 0.666, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.6412, loss: 0.6412\n",
      "2022-03-23 22:59:06,581 - mmaction - INFO - Saving checkpoint at 7 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 38s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:00:00,707 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 23:00:00,708 - mmaction - INFO - \n",
      "top1_acc\t0.8983\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 23:00:00,711 - mmaction - INFO - Epoch(val) [7][30]\ttop1_acc: 0.8983, top5_acc: 1.0000, loss_cls: 0.3461, loss: 0.3461\n",
      "2022-03-23 23:00:18,143 - mmaction - INFO - Epoch [8][20/109]\tlr: 8.716e-05, eta: 0:27:01, time: 0.871, data_time: 0.206, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4950, loss: 0.4950\n",
      "2022-03-23 23:00:31,414 - mmaction - INFO - Epoch [8][40/109]\tlr: 8.716e-05, eta: 0:26:49, time: 0.664, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4405, loss: 0.4405\n",
      "2022-03-23 23:00:44,718 - mmaction - INFO - Epoch [8][60/109]\tlr: 8.716e-05, eta: 0:26:36, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3251, loss: 0.3251\n",
      "2022-03-23 23:00:58,028 - mmaction - INFO - Epoch [8][80/109]\tlr: 8.716e-05, eta: 0:26:24, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3706, loss: 0.3706\n",
      "2022-03-23 23:01:11,380 - mmaction - INFO - Epoch [8][100/109]\tlr: 8.716e-05, eta: 0:26:12, time: 0.668, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5947, loss: 0.5947\n",
      "2022-03-23 23:01:17,151 - mmaction - INFO - Saving checkpoint at 8 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:02:12,102 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 23:02:12,103 - mmaction - INFO - \n",
      "top1_acc\t0.8136\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 23:02:12,105 - mmaction - INFO - Epoch(val) [8][30]\ttop1_acc: 0.8136, top5_acc: 1.0000, loss_cls: 0.5509, loss: 0.5509\n",
      "2022-03-23 23:02:28,822 - mmaction - INFO - Epoch [9][20/109]\tlr: 8.346e-05, eta: 0:25:47, time: 0.836, data_time: 0.172, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3813, loss: 0.3813\n",
      "2022-03-23 23:02:42,080 - mmaction - INFO - Epoch [9][40/109]\tlr: 8.346e-05, eta: 0:25:35, time: 0.663, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3377, loss: 0.3377\n",
      "2022-03-23 23:02:55,379 - mmaction - INFO - Epoch [9][60/109]\tlr: 8.346e-05, eta: 0:25:22, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.6669, loss: 0.6669\n",
      "2022-03-23 23:03:08,695 - mmaction - INFO - Epoch [9][80/109]\tlr: 8.346e-05, eta: 0:25:10, time: 0.666, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4182, loss: 0.4182\n",
      "2022-03-23 23:03:22,025 - mmaction - INFO - Epoch [9][100/109]\tlr: 8.346e-05, eta: 0:24:58, time: 0.666, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.4884, loss: 0.4884\n",
      "2022-03-23 23:03:27,769 - mmaction - INFO - Saving checkpoint at 9 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:04:22,058 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 23:04:22,059 - mmaction - INFO - \n",
      "top1_acc\t0.7797\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 23:04:22,061 - mmaction - INFO - Epoch(val) [9][30]\ttop1_acc: 0.7797, top5_acc: 1.0000, loss_cls: 0.6307, loss: 0.6307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:04:38,796 - mmaction - INFO - Epoch [10][20/109]\tlr: 7.939e-05, eta: 0:24:34, time: 0.837, data_time: 0.174, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5887, loss: 0.5887\n",
      "2022-03-23 23:04:52,058 - mmaction - INFO - Epoch [10][40/109]\tlr: 7.939e-05, eta: 0:24:21, time: 0.663, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2796, loss: 0.2796\n",
      "2022-03-23 23:05:05,339 - mmaction - INFO - Epoch [10][60/109]\tlr: 7.939e-05, eta: 0:24:09, time: 0.664, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3674, loss: 0.3674\n",
      "2022-03-23 23:05:18,647 - mmaction - INFO - Epoch [10][80/109]\tlr: 7.939e-05, eta: 0:23:57, time: 0.665, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4119, loss: 0.4119\n",
      "2022-03-23 23:05:31,971 - mmaction - INFO - Epoch [10][100/109]\tlr: 7.939e-05, eta: 0:23:44, time: 0.666, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2579, loss: 0.2579\n",
      "2022-03-23 23:05:37,728 - mmaction - INFO - Saving checkpoint at 10 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:06:15,751 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 23:06:15,752 - mmaction - INFO - \n",
      "top1_acc\t0.8136\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 23:06:15,753 - mmaction - INFO - Evaluating mean_class_accuracy ...\n",
      "2022-03-23 23:06:15,754 - mmaction - INFO - \n",
      "mean_acc\t0.8244\n",
      "2022-03-23 23:06:15,755 - mmaction - INFO - Epoch(val) [10][59]\ttop1_acc: 0.8136, top5_acc: 1.0000, mean_class_accuracy: 0.8244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 37s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:07:07,418 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 23:07:07,419 - mmaction - INFO - \n",
      "top1_acc\t0.8136\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 23:07:07,421 - mmaction - INFO - Epoch(val) [10][30]\ttop1_acc: 0.8136, top5_acc: 1.0000, loss_cls: 0.5244, loss: 0.5244\n",
      "2022-03-23 23:07:23,562 - mmaction - INFO - Epoch [11][20/109]\tlr: 7.500e-05, eta: 0:23:20, time: 0.807, data_time: 0.143, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.4174, loss: 0.4174\n",
      "2022-03-23 23:07:36,796 - mmaction - INFO - Epoch [11][40/109]\tlr: 7.500e-05, eta: 0:23:08, time: 0.662, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2417, loss: 0.2417\n",
      "2022-03-23 23:07:50,051 - mmaction - INFO - Epoch [11][60/109]\tlr: 7.500e-05, eta: 0:22:55, time: 0.663, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.3538, loss: 0.3538\n",
      "2022-03-23 23:08:03,318 - mmaction - INFO - Epoch [11][80/109]\tlr: 7.500e-05, eta: 0:22:43, time: 0.663, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5408, loss: 0.5408\n",
      "2022-03-23 23:08:16,606 - mmaction - INFO - Epoch [11][100/109]\tlr: 7.500e-05, eta: 0:22:30, time: 0.664, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.5747, loss: 0.5747\n",
      "2022-03-23 23:08:22,348 - mmaction - INFO - Saving checkpoint at 11 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.6 task/s, elapsed: 36s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:09:15,595 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 23:09:15,596 - mmaction - INFO - \n",
      "top1_acc\t0.7627\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 23:09:15,598 - mmaction - INFO - Epoch(val) [11][30]\ttop1_acc: 0.7627, top5_acc: 1.0000, loss_cls: 0.7005, loss: 0.7005\n",
      "2022-03-23 23:09:32,601 - mmaction - INFO - Epoch [12][20/109]\tlr: 7.034e-05, eta: 0:22:08, time: 0.850, data_time: 0.186, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4679, loss: 0.4679\n",
      "2022-03-23 23:09:45,884 - mmaction - INFO - Epoch [12][40/109]\tlr: 7.034e-05, eta: 0:21:56, time: 0.664, data_time: 0.000, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.2493, loss: 0.2493\n",
      "2022-03-23 23:09:59,231 - mmaction - INFO - Epoch [12][60/109]\tlr: 7.034e-05, eta: 0:21:44, time: 0.667, data_time: 0.000, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.4796, loss: 0.4796\n",
      "2022-03-23 23:10:12,622 - mmaction - INFO - Epoch [12][80/109]\tlr: 7.034e-05, eta: 0:21:31, time: 0.670, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3261, loss: 0.3261\n",
      "2022-03-23 23:10:26,075 - mmaction - INFO - Epoch [12][100/109]\tlr: 7.034e-05, eta: 0:21:19, time: 0.673, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2812, loss: 0.2812\n",
      "2022-03-23 23:10:31,903 - mmaction - INFO - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 59/59, 1.7 task/s, elapsed: 34s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-23 23:11:21,451 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-03-23 23:11:21,452 - mmaction - INFO - \n",
      "top1_acc\t0.7797\n",
      "top5_acc\t1.0000\n",
      "2022-03-23 23:11:21,454 - mmaction - INFO - Epoch(val) [12][30]\ttop1_acc: 0.7797, top5_acc: 1.0000, loss_cls: 0.5825, loss: 0.5825\n",
      "2022-03-23 23:11:38,229 - mmaction - INFO - Epoch [13][20/109]\tlr: 6.545e-05, eta: 0:20:57, time: 0.838, data_time: 0.161, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.4970, loss: 0.4970\n",
      "2022-03-23 23:11:51,777 - mmaction - INFO - Epoch [13][40/109]\tlr: 6.545e-05, eta: 0:20:45, time: 0.677, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.3825, loss: 0.3825\n",
      "2022-03-23 23:12:05,406 - mmaction - INFO - Epoch [13][60/109]\tlr: 6.545e-05, eta: 0:20:33, time: 0.681, data_time: 0.000, memory: 2835, top1_acc: 0.9750, top5_acc: 1.0000, loss_cls: 0.1108, loss: 0.1108\n",
      "2022-03-23 23:12:19,111 - mmaction - INFO - Epoch [13][80/109]\tlr: 6.545e-05, eta: 0:20:21, time: 0.685, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4256, loss: 0.4256\n",
      "2022-03-23 23:12:32,856 - mmaction - INFO - Epoch [13][100/109]\tlr: 6.545e-05, eta: 0:20:09, time: 0.687, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5157, loss: 0.5157\n",
      "2022-03-23 23:12:38,789 - mmaction - INFO - Saving checkpoint at 13 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>                           ] 11/59, 1.0 task/s, elapsed: 11s, ETA:    50s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m runner_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrunner_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:127\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs:\n\u001b[1;32m    126\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m             \u001b[43mepoch_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py:70\u001b[0m, in \u001b[0;36mEpochBasedRunner.val\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_iter(data_batch, train_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_val_iter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mafter_val_epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmcv/runner/base_runner.py:307\u001b[0m, in \u001b[0;36mBaseRunner.call_hook\u001b[0;34m(self, fn_name)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m\"\"\"Call all hooks.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \n\u001b[1;32m    302\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    fn_name (str): The function name in each hook to be called, such as\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;124;03m        \"before_train_epoch\".\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mWandBHook.after_val_epoch\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mafter_val_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m, runner):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124;03m\"\"\"Called after every validation epoch to evaluate the results.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36mWandBHook._do_evaluate\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, runner):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;124;03m\"\"\"perform evaluation and save ckpt.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43msingle_gpu_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     eval_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mevaluate(results, logger\u001b[38;5;241m=\u001b[39mrunner\u001b[38;5;241m.\u001b[39mlogger, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_kwargs)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwandb\u001b[38;5;241m.\u001b[39mlog(eval_res)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmcv/engine/test.py:33\u001b[0m, in \u001b[0;36msingle_gpu_test\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 33\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     results\u001b[38;5;241m.\u001b[39mextend(result)\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Assume result has the same length of batch_size\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# refer to https://github.com/open-mmlab/mmcv/issues/985\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py:50\u001b[0m, in \u001b[0;36mMMDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:166\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/Video-Swin-Transformer/mmaction/models/recognizers/base.py:258\u001b[0m, in \u001b[0;36mBaseRecognizer.forward\u001b[0;34m(self, imgs, label, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m         imgs, label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblending(imgs, label)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_train(imgs, label, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/Video-Swin-Transformer/mmaction/models/recognizers/recognizer3d.py:90\u001b[0m, in \u001b[0;36mRecognizer3D.forward_test\u001b[0;34m(self, imgs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_test\u001b[39m(\u001b[38;5;28mself\u001b[39m, imgs):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124;03m\"\"\"Defines the computation performed at every call when evaluation and\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m    testing.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/apex/amp/wrap.py:28\u001b[0m, in \u001b[0;36mmake_cast_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m             kwargs[k] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcached_cast(cast_fn, kwargs[k], handle\u001b[38;5;241m.\u001b[39mcache)\n\u001b[1;32m     25\u001b[0m new_args \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcasted_args(cast_fn,\n\u001b[1;32m     26\u001b[0m                              args,\n\u001b[1;32m     27\u001b[0m                              kwargs)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43morig_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "runner_kwargs = dict()\n",
    "runner.run(data_loaders, cfg.workflow, cfg.total_epochs, **runner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da66c68-4b16-4ffb-b79f-1847e3355d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343d7a4-fcbb-482d-8002-f9233fba7510",
   "metadata": {},
   "source": [
    "## Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e95cd6-16cc-4bbd-94df-8a9dd18b6872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # init distributed env first, since logger depends on the dist info.\n",
    "# if args.launcher == 'none':\n",
    "#     distributed = False\n",
    "# else:\n",
    "#     distributed = True\n",
    "#     init_dist(args.launcher, **cfg.dist_params)\n",
    "#     _, world_size = get_dist_info()\n",
    "#     cfg.gpu_ids = range(world_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
