{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a7aed7-6b2a-4081-8ed3-7847c97ac7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../Video-Swin-Transformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5c1440-6b87-41d0-814a-b275108a97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change teh working directory to a location that the code prefers\n",
    "os.chdir(\"../Video-Swin-Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e4a28c-4e43-4cde-8e9a-3d7236acb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist, set_random_seed\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmaction import __version__\n",
    "from mmaction.apis import train_model\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.utils import collect_env, get_root_logger, register_module_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ea8e512-db21-4cb2-9101-305199748aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c521d7ba-77f0-4cc9-8dd2-9a426f07b409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maswin_thiru\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Log in to your W&B account\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "824ca902-3e0b-48f7-8bd2-57db303a9959",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_project_name = 'bsl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "befe8d30-137b-48ee-8fff-5f6c81f50d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import test functions from mmcv and delete them from mmaction2\n",
    "try:\n",
    "    from mmcv.engine import multi_gpu_test, single_gpu_test\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    warnings.warn(\n",
    "        'DeprecationWarning: single_gpu_test, multi_gpu_test, '\n",
    "        'collect_results_cpu, collect_results_gpu from mmaction2 will be '\n",
    "        'deprecated. Please install mmcv through master branch.')\n",
    "    from mmaction.apis import multi_gpu_test, single_gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "790667cc-bad1-43c0-9df4-a7e86c65dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(parse_options=None):\n",
    "    parser = argparse.ArgumentParser(description='Train a recognizer')\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    parser.add_argument(\n",
    "        '--load-from', help='the checkpoint file to load from')\n",
    "    parser.add_argument(\n",
    "        '--validate',\n",
    "        action='store_true',\n",
    "        help='whether to evaluate the checkpoint during training')\n",
    "    parser.add_argument(\n",
    "        '--test-last',\n",
    "        action='store_true',\n",
    "        help='whether to test the checkpoint after training')\n",
    "    parser.add_argument(\n",
    "        '--test-best',\n",
    "        action='store_true',\n",
    "        help=('whether to test the best checkpoint (if applicable) after '\n",
    "              'training'))\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        default={},\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. For example, '\n",
    "        \"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\")\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    \n",
    "    if parse_options is None: \n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(parse_options)\n",
    "        \n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5baa4b97-74b5-4082-9a12-3cf378f11bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the cofiguration and data file\n",
    "config_file = '../configs/bsl_config.py'\n",
    "check_point_file = '../configs/swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
    "# , \"model.backbone.pretrained=\"+check_point_file\n",
    "# cmd_options = [config_file, \"--cfg-options\", \"model.backbone.use_checkpoint=True\", \"--load-from\", check_point_file,\n",
    "#                \"--seed\", \"12345\"]\n",
    "cmd_options = [config_file, \"--cfg-options\", \"model.backbone.use_checkpoint=True\", \"--load-from\", check_point_file,\n",
    "              \"--validate\", \"--seed\", \"12345\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fdd078b-640c-4500-bfb6-737ccde06ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "distributed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e35d5ede-d413-405f-9fce-5be60ba5183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py\n",
      "../Video-Swin-Transformer/configs/_base_/default_runtime.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:35:12,321 - mmaction - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]\n",
      "CUDA available: True\n",
      "GPU 0: Tesla T4\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Build cuda_11.6.r11.6/compiler.30794723_0\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n",
      "PyTorch: 1.11.0a0+17540c5\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.3.3 (Git Hash N/A)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_86,code=compute_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS=-fno-gnu-unique -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0a0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.4.0\n",
      "MMCV Compiler: GCC 9.3\n",
      "MMCV CUDA Compiler: not available\n",
      "MMAction2: 0.15.0+db018fb\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-04-08 00:35:12,322 - mmaction - INFO - Distributed training: False\n",
      "2022-04-08 00:35:12,544 - mmaction - INFO - Config: model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer3D',\n",
      "        patch_size=(2, 4, 4),\n",
      "        embed_dim=96,\n",
      "        depths=[2, 2, 6, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        window_size=(8, 7, 7),\n",
      "        mlp_ratio=4.0,\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        patch_norm=True,\n",
      "        use_checkpoint=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        in_channels=768,\n",
      "        num_classes=5,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5),\n",
      "    test_cfg=dict(average_clips='prob', max_testing_views=4))\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '../configs/swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1), ('val', 1)]\n",
      "swin_tiny_path = '../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py'\n",
      "runtime_path = '../Video-Swin-Transformer/configs/_base_/default_runtime.py'\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = '../processed_videos'\n",
      "data_root_val = '../processed_videos/val'\n",
      "data_root_test = '../processed_videos/test'\n",
      "data_root_train = '../processed_videos/train'\n",
      "ann_file_val = '../processed_videos/bsl_val_video.txt'\n",
      "ann_file_test = '../processed_videos/bsl_test_video.txt'\n",
      "ann_file_train = '../processed_videos/bsl_train_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 224)),\n",
      "    dict(type='ThreeCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    val_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    test_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_train_video.txt',\n",
      "        data_prefix='../processed_videos/train',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_val_video.txt',\n",
      "        data_prefix='../processed_videos/val',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../processed_videos/bsl_test_video.txt',\n",
      "        data_prefix='../processed_videos/test',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 224)),\n",
      "            dict(type='ThreeCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.001,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.02,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            backbone=dict(lr_mult=0.1))))\n",
      "lr_config = dict(\n",
      "    policy='CosineAnnealing',\n",
      "    min_lr=0,\n",
      "    warmup='linear',\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=2.5)\n",
      "total_epochs = 15\n",
      "work_dir = './work_dirs/k400_swin_tiny_patch244_window877.py'\n",
      "find_unused_parameters = False\n",
      "fp16 = None\n",
      "optimizer_config = dict(\n",
      "    type='DistOptimizerHook',\n",
      "    update_interval=4,\n",
      "    grad_clip=None,\n",
      "    coalesce=True,\n",
      "    bucket_size_mb=-1,\n",
      "    use_fp16=True)\n",
      "gpu_ids = range(0, 1)\n",
      "omnisource = False\n",
      "module_hooks = []\n",
      "\n",
      "2022-04-08 00:35:12,545 - mmaction - INFO - Set random seed to 12345, deterministic: False\n"
     ]
    }
   ],
   "source": [
    "# Create a configuration object that describes the training and testing\n",
    "args = parse_args(cmd_options)\n",
    "cfg = Config.fromfile(args.config)\n",
    "cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "# Customization for training the BSL data set\n",
    "# https://mmcv.readthedocs.io/en/latest/_modules/mmcv/runner/epoch_based_runner.html\n",
    "cfg.workflow = [('train', 1), ('val', 1)]\n",
    "# cfg.workflow = [('train', 1), ]\n",
    "cfg.model.cls_head.num_classes = 5\n",
    "\n",
    "# Resume from this pyhton checkpoint file\n",
    "cfg.resume_from = args.resume_from\n",
    "cfg.load_from = args.load_from\n",
    "\n",
    "# One GPU\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# The flag is used to determine whether it is omnisource training\n",
    "# Omnisource reference: https://arxiv.org/abs/2003.13042\n",
    "cfg.setdefault('omnisource', False)\n",
    "\n",
    "# The flag is used to register module's hooks\n",
    "cfg.setdefault('module_hooks', [])\n",
    "\n",
    "# create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# dump config\n",
    "cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))\n",
    "\n",
    "# init logger before other steps\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "# init the meta dict to record some important information such as\n",
    "# environment info and seed, which will be logged\n",
    "meta = dict()\n",
    "# log env info\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([f'{k}: {v}' for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "            dash_line)\n",
    "meta['env_info'] = env_info\n",
    "\n",
    "# log some basic info\n",
    "logger.info(f'Distributed training: {distributed}')\n",
    "logger.info(f'Config: {cfg.pretty_text}')\n",
    "\n",
    "# Set seed for training\n",
    "logger.info(f'Set random seed to {args.seed}, '\n",
    "            f'deterministic: {args.deterministic}')\n",
    "set_random_seed(args.seed, deterministic=args.deterministic)\n",
    "\n",
    "cfg.seed = args.seed\n",
    "meta['seed'] = args.seed\n",
    "meta['config_name'] = osp.basename(args.config)\n",
    "meta['work_dir'] = osp.basename(cfg.work_dir.rstrip('/\\\\'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f965ec0-5475-4d9e-8680-1750367df750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Validation is setup as a hook that kicks off every 5 iterations\n",
    "# This is required for wandb to kickk off every iteration\n",
    "if 1:\n",
    "    # Create the validation dataset\n",
    "    val_dataset = copy.deepcopy(cfg.data.val)\n",
    "    datasets.append(build_dataset(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78afc72a-490e-4cf5-ab6d-1af0f142038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in val_dataset:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa7e7dbf-ff4b-4981-8a8c-55c05d84c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model to test after training, best or last?\n",
    "test_option = dict(test_last=args.test_last, test_best=args.test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec18ba5-c4f7-46ba-ad56-d574be3b163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:2166.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Build the model for \n",
    "model = build_model(cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46cee06-3b44-484b-954b-6fb7558b2705",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a2c7cb-8783-42b7-9480-f45be536428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import apex\n",
    "from mmaction.core import DistEvalHook, EvalHook\n",
    "from mmaction.datasets import build_dataloader, build_dataset\n",
    "from mmcv_custom.runner import EpochBasedRunnerAmp\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "from mmcv.runner import DistSamplerSeedHook, EpochBasedRunner, OptimizerHook, build_optimizer, get_dist_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10252d76-7ef6-429d-9ae4-a386c33d996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the root logger\n",
    "logger = get_root_logger(log_level=cfg.log_level)\n",
    "\n",
    "\n",
    "# Load the data using the GPU\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1) // cfg.optimizer_config.get('update_interval', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    num_gpus=len(cfg.gpu_ids),\n",
    "    dist=distributed,\n",
    "    seed=cfg.seed)\n",
    "\n",
    "# \n",
    "dataloader_setting = dict(dataloader_setting, **cfg.data.get('train_dataloader', {}))\n",
    "data_loaders = [build_dataloader(ds, **dataloader_setting) for ds in datasets]\n",
    "\n",
    "# \n",
    "val_dataset = build_dataset(cfg.data.val, dict(test_mode=True))\n",
    "dataloader_setting = dict(\n",
    "    videos_per_gpu=cfg.data.get('videos_per_gpu', 1),\n",
    "    workers_per_gpu=cfg.data.get('workers_per_gpu', 1),\n",
    "    # cfg.gpus will be ignored if distributed\n",
    "    num_gpus=len(cfg.gpu_ids),\n",
    "    dist=distributed,\n",
    "    shuffle=False)\n",
    "\n",
    "dataloader_setting = dict(dataloader_setting, **cfg.data.get('val_dataloader', {}))\n",
    "val_dataloader = build_dataloader(val_dataset, **dataloader_setting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "759d0fa4-56c1-46ad-a5ad-646407d4607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "# build optimizer\n",
    "optimizer = build_optimizer(model, cfg.optimizer)\n",
    "model, optimizer = apex.amp.initialize(model.cuda(), optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "280c1f8d-1086-4279-8b9f-1d65ad3daadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in model.modules():\n",
    "    if hasattr(m, \"fp16_enabled\"):\n",
    "        m.fp16_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d911e1dc-184e-4f32-9730-7861f5d6282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the model on GPU's for training\n",
    "if distributed:\n",
    "    find_unused_parameters = cfg.get('find_unused_parameters', False)\n",
    "    # Sets the `find_unused_parameters` parameter in\n",
    "    # torch.nn.parallel.DistributedDataParallel\n",
    "    model = MMDistributedDataParallel(\n",
    "        model.cuda(),\n",
    "        device_ids=[torch.cuda.current_device()],\n",
    "        broadcast_buffers=False,\n",
    "        find_unused_parameters=find_unused_parameters)\n",
    "else:\n",
    "    model = MMDataParallel(\n",
    "        model.cuda(cfg.gpu_ids[0]), device_ids=cfg.gpu_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f756b41b-ec1a-4f95-88ee-ec56959f4a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the class that will run the code \n",
    "Runner = EpochBasedRunnerAmp\n",
    "runner = Runner(model, optimizer=optimizer, work_dir=cfg.work_dir, logger=logger, meta=meta)\n",
    "\n",
    "# an ugly workaround to make .log and .log.json filenames the same\n",
    "runner.timestamp = timestamp\n",
    "\n",
    "# \n",
    "optimizer_config = cfg.optimizer_config\n",
    "\n",
    "# register hooks\n",
    "runner.register_training_hooks(cfg.lr_config, optimizer_config, cfg.checkpoint_config, cfg.log_config, cfg.get('momentum_config', None))\n",
    "\n",
    "if distributed:\n",
    "    runner.register_hook(DistSamplerSeedHook())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "722a52fc-f7f5-4303-99f9-321461dc2c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# eval_cfg = cfg.get('evaluation', {})\n",
    "# eval_hook = DistEvalHook if distributed else EvalHook\n",
    "# runner.register_hook(eval_hook(val_dataloader, **eval_cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f27dcb4-8d84-4f8a-b711-04e09020986c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:35:14,731 - mmaction - INFO - load checkpoint from local path: ../configs/swin_tiny_patch244_window877_kinetics400_1k.pth\n",
      "2022-04-08 00:35:14,834 - mmaction - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 768]) from checkpoint, the shape in current model is torch.Size([5, 768]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([5]).\n"
     ]
    }
   ],
   "source": [
    "if cfg.resume_from:\n",
    "    runner.resume(cfg.resume_from, resume_amp=use_amp)\n",
    "elif cfg.get(\"auto_resume\", False) and osp.exists(osp.join(runner.work_dir, 'latest.pth')):\n",
    "    runner.auto_resume()\n",
    "elif cfg.load_from:\n",
    "    runner.load_checkpoint(cfg.load_from)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13aeb1d-ccb6-4d8a-8fd0-d9839234182f",
   "metadata": {},
   "source": [
    "## Dashboarding using wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "113ae2f6-b4f6-40cf-b784-02f92c49cbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.13"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/Video-Swin-Transformer/wandb/run-20220408_003514-irmgu9ef</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/aswin_thiru/bsl/runs/irmgu9ef\" target=\"_blank\">cerulean-butterfly-10</a></strong> to <a href=\"https://wandb.ai/aswin_thiru/bsl\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/aswin_thiru/bsl/runs/irmgu9ef?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f296123e790>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=wandb_project_name, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eebc0db-2f00-465e-9a18-edd56817a3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.runner import Hook\n",
    "from torch.utils.data import DataLoader\n",
    "from mmaction.apis import single_gpu_test\n",
    "\n",
    "\n",
    "class WandBHook(Hook):  # noqa: F811\n",
    "    \"\"\"Non-Distributed evaluation hook.\n",
    "\n",
    "    Notes:\n",
    "        If new arguments are added for EvalHook, tools/test.py,\n",
    "        tools/eval_metric.py may be effected.\n",
    "\n",
    "    This hook will regularly perform evaluation in a given interval when\n",
    "    performing in non-distributed environment.\n",
    "\n",
    "    Args:\n",
    "        dataloader (DataLoader): A PyTorch dataloader.\n",
    "        wandb_obj: A wandb object\n",
    "        optimizer_obj: optimizer object\n",
    "        **eval_kwargs: Evaluation arguments fed into the evaluate function\n",
    "            of the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataloader,\n",
    "                 wandb_obj,\n",
    "                 optimizer_obj,\n",
    "                 **eval_kwargs):\n",
    "\n",
    "        if not isinstance(dataloader, DataLoader):\n",
    "            raise TypeError(f'dataloader must be a pytorch DataLoader, '\n",
    "                            f'but got {type(dataloader)}')\n",
    "\n",
    "        self.dataloader = dataloader\n",
    "        self.wandb = wandb\n",
    "        self.eval_kwargs = eval_kwargs\n",
    "    \n",
    "    def before_train_epoch(self, runner):\n",
    "        \"\"\"Called after every train epoch to save learning rate\"\"\"\n",
    "        self.wandb.log({\"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "    def after_val_epoch(self, runner):\n",
    "        \"\"\"Called after every validation epoch to evaluate the results.\"\"\"\n",
    "        self._do_evaluate(runner)\n",
    "\n",
    "    def _do_evaluate(self, runner):\n",
    "        results = single_gpu_test(runner.model, self.dataloader)\n",
    "        eval_res = self.dataloader.dataset.evaluate(results, logger=runner.logger, **self.eval_kwargs)\n",
    "        self.wandb.log(eval_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00329ab1-9f35-4ee8-88cc-0cecd0ac86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.register_hook(WandBHook(val_dataloader, wandb, optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c46dbe0e-bcea-4b42-bbde-4ba6fb18a81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:35:16,724 - mmaction - INFO - Start running, host: root@ip-10-0-0-144, work_dir: /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py\n",
      "2022-04-08 00:35:16,724 - mmaction - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(NORMAL      ) WandBHook                          \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(NORMAL      ) WandBHook                          \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-04-08 00:35:16,725 - mmaction - INFO - workflow: [('train', 1), ('val', 1)], max: 15 epochs\n",
      "2022-04-08 00:35:16,726 - mmaction - INFO - Checkpoints will be saved to /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py by HardDiskBackend.\n",
      "2022-04-08 00:35:35,273 - mmaction - INFO - Epoch [1][20/111]\tlr: 1.616e-05, eta: 0:25:25, time: 0.927, data_time: 0.182, memory: 2832, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 1.5963, loss: 1.5963\n",
      "2022-04-08 00:35:48,277 - mmaction - INFO - Epoch [1][40/111]\tlr: 2.265e-05, eta: 0:21:21, time: 0.650, data_time: 0.001, memory: 2832, top1_acc: 0.2000, top5_acc: 1.0000, loss_cls: 1.6342, loss: 1.6342\n",
      "2022-04-08 00:36:01,283 - mmaction - INFO - Epoch [1][60/111]\tlr: 2.914e-05, eta: 0:19:51, time: 0.650, data_time: 0.001, memory: 2832, top1_acc: 0.0500, top5_acc: 1.0000, loss_cls: 1.6424, loss: 1.6424\n",
      "2022-04-08 00:36:14,280 - mmaction - INFO - Epoch [1][80/111]\tlr: 3.562e-05, eta: 0:19:00, time: 0.650, data_time: 0.001, memory: 2832, top1_acc: 0.3750, top5_acc: 1.0000, loss_cls: 1.5847, loss: 1.5847\n",
      "2022-04-08 00:36:27,272 - mmaction - INFO - Epoch [1][100/111]\tlr: 4.211e-05, eta: 0:18:23, time: 0.650, data_time: 0.001, memory: 2832, top1_acc: 0.4000, top5_acc: 1.0000, loss_cls: 1.5560, loss: 1.5560\n",
      "2022-04-08 00:36:34,133 - mmaction - INFO - Saving checkpoint at 1 epochs\n",
      "/opt/conda/lib/python3.8/site-packages/torch/utils/checkpoint.py:25: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:37:03,966 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:37:03,967 - mmaction - INFO - \n",
      "top1_acc\t0.4182\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:37:03,969 - mmaction - INFO - Epoch(val) [1][28]\ttop1_acc: 0.4182, top5_acc: 1.0000, loss_cls: 1.5456, loss: 1.5456\n",
      "2022-04-08 00:37:19,872 - mmaction - INFO - Epoch [2][20/111]\tlr: 5.159e-05, eta: 0:16:52, time: 0.795, data_time: 0.144, memory: 2833, top1_acc: 0.5250, top5_acc: 1.0000, loss_cls: 1.5009, loss: 1.5009\n",
      "2022-04-08 00:37:32,880 - mmaction - INFO - Epoch [2][40/111]\tlr: 5.801e-05, eta: 0:16:37, time: 0.650, data_time: 0.001, memory: 2833, top1_acc: 0.5500, top5_acc: 1.0000, loss_cls: 1.4020, loss: 1.4020\n",
      "2022-04-08 00:37:45,885 - mmaction - INFO - Epoch [2][60/111]\tlr: 6.442e-05, eta: 0:16:22, time: 0.650, data_time: 0.000, memory: 2835, top1_acc: 0.6500, top5_acc: 1.0000, loss_cls: 1.3075, loss: 1.3075\n",
      "2022-04-08 00:37:58,914 - mmaction - INFO - Epoch [2][80/111]\tlr: 7.084e-05, eta: 0:16:08, time: 0.651, data_time: 0.000, memory: 2835, top1_acc: 0.5500, top5_acc: 1.0000, loss_cls: 1.2491, loss: 1.2491\n",
      "2022-04-08 00:38:11,943 - mmaction - INFO - Epoch [2][100/111]\tlr: 7.725e-05, eta: 0:15:54, time: 0.651, data_time: 0.000, memory: 2835, top1_acc: 0.5750, top5_acc: 1.0000, loss_cls: 1.1033, loss: 1.1033\n",
      "2022-04-08 00:38:18,862 - mmaction - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:38:48,875 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:38:48,877 - mmaction - INFO - \n",
      "top1_acc\t0.5818\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:38:48,879 - mmaction - INFO - Epoch(val) [2][28]\ttop1_acc: 0.5818, top5_acc: 1.0000, loss_cls: 1.0687, loss: 1.0687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:39:04,757 - mmaction - INFO - Epoch [3][20/111]\tlr: 8.435e-05, eta: 0:15:07, time: 0.794, data_time: 0.139, memory: 2835, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 1.1830, loss: 1.1830\n",
      "2022-04-08 00:39:17,834 - mmaction - INFO - Epoch [3][40/111]\tlr: 9.056e-05, eta: 0:14:56, time: 0.654, data_time: 0.000, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.8476, loss: 0.8476\n",
      "2022-04-08 00:39:30,936 - mmaction - INFO - Epoch [3][60/111]\tlr: 9.552e-05, eta: 0:14:45, time: 0.655, data_time: 0.000, memory: 2835, top1_acc: 0.6250, top5_acc: 1.0000, loss_cls: 0.9983, loss: 0.9983\n",
      "2022-04-08 00:39:44,118 - mmaction - INFO - Epoch [3][80/111]\tlr: 9.552e-05, eta: 0:14:34, time: 0.659, data_time: 0.000, memory: 2835, top1_acc: 0.6250, top5_acc: 1.0000, loss_cls: 0.9227, loss: 0.9227\n",
      "2022-04-08 00:39:57,377 - mmaction - INFO - Epoch [3][100/111]\tlr: 9.552e-05, eta: 0:14:23, time: 0.663, data_time: 0.001, memory: 2835, top1_acc: 0.6000, top5_acc: 1.0000, loss_cls: 0.8774, loss: 0.8774\n",
      "2022-04-08 00:40:04,415 - mmaction - INFO - Saving checkpoint at 3 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:40:34,036 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:40:34,037 - mmaction - INFO - \n",
      "top1_acc\t0.7455\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:40:34,039 - mmaction - INFO - Epoch(val) [3][28]\ttop1_acc: 0.7455, top5_acc: 1.0000, loss_cls: 0.5884, loss: 0.5884\n",
      "2022-04-08 00:40:50,455 - mmaction - INFO - Epoch [4][20/111]\tlr: 9.045e-05, eta: 0:13:50, time: 0.821, data_time: 0.151, memory: 2835, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.8423, loss: 0.8423\n",
      "2022-04-08 00:41:03,859 - mmaction - INFO - Epoch [4][40/111]\tlr: 9.045e-05, eta: 0:13:40, time: 0.670, data_time: 0.000, memory: 2835, top1_acc: 0.6750, top5_acc: 1.0000, loss_cls: 0.8360, loss: 0.8360\n",
      "2022-04-08 00:41:17,313 - mmaction - INFO - Epoch [4][60/111]\tlr: 9.045e-05, eta: 0:13:30, time: 0.673, data_time: 0.001, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.4526, loss: 0.4526\n",
      "2022-04-08 00:41:30,813 - mmaction - INFO - Epoch [4][80/111]\tlr: 9.045e-05, eta: 0:13:19, time: 0.675, data_time: 0.000, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.6291, loss: 0.6291\n",
      "2022-04-08 00:41:44,406 - mmaction - INFO - Epoch [4][100/111]\tlr: 9.045e-05, eta: 0:13:09, time: 0.680, data_time: 0.000, memory: 2835, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.7724, loss: 0.7724\n",
      "2022-04-08 00:41:51,639 - mmaction - INFO - Saving checkpoint at 4 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:42:21,803 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:42:21,804 - mmaction - INFO - \n",
      "top1_acc\t0.7273\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:42:21,807 - mmaction - INFO - Epoch(val) [4][28]\ttop1_acc: 0.7273, top5_acc: 1.0000, loss_cls: 0.7427, loss: 0.7427\n",
      "2022-04-08 00:42:38,999 - mmaction - INFO - Epoch [5][20/111]\tlr: 8.346e-05, eta: 0:12:42, time: 0.859, data_time: 0.174, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5533, loss: 0.5533\n",
      "2022-04-08 00:42:52,787 - mmaction - INFO - Epoch [5][40/111]\tlr: 8.346e-05, eta: 0:12:32, time: 0.689, data_time: 0.001, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.7710, loss: 0.7710\n",
      "2022-04-08 00:43:06,582 - mmaction - INFO - Epoch [5][60/111]\tlr: 8.346e-05, eta: 0:12:22, time: 0.690, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.6118, loss: 0.6118\n",
      "2022-04-08 00:43:20,440 - mmaction - INFO - Epoch [5][80/111]\tlr: 8.346e-05, eta: 0:12:11, time: 0.693, data_time: 0.000, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.6964, loss: 0.6964\n",
      "2022-04-08 00:43:34,308 - mmaction - INFO - Epoch [5][100/111]\tlr: 8.346e-05, eta: 0:12:00, time: 0.693, data_time: 0.000, memory: 2835, top1_acc: 0.7000, top5_acc: 1.0000, loss_cls: 0.7209, loss: 0.7209\n",
      "2022-04-08 00:43:41,607 - mmaction - INFO - Saving checkpoint at 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.8 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:44:11,646 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:44:11,648 - mmaction - INFO - \n",
      "top1_acc\t0.8364\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:44:11,650 - mmaction - INFO - Epoch(val) [5][28]\ttop1_acc: 0.8364, top5_acc: 1.0000, loss_cls: 0.3528, loss: 0.3528\n",
      "2022-04-08 00:44:28,258 - mmaction - INFO - Epoch [6][20/111]\tlr: 7.500e-05, eta: 0:11:34, time: 0.830, data_time: 0.145, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.4963, loss: 0.4963\n",
      "2022-04-08 00:44:42,033 - mmaction - INFO - Epoch [6][40/111]\tlr: 7.500e-05, eta: 0:11:23, time: 0.689, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.5577, loss: 0.5577\n",
      "2022-04-08 00:44:55,858 - mmaction - INFO - Epoch [6][60/111]\tlr: 7.500e-05, eta: 0:11:12, time: 0.691, data_time: 0.000, memory: 2835, top1_acc: 0.7250, top5_acc: 1.0000, loss_cls: 0.6180, loss: 0.6180\n",
      "2022-04-08 00:45:09,717 - mmaction - INFO - Epoch [6][80/111]\tlr: 7.500e-05, eta: 0:11:01, time: 0.693, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.6108, loss: 0.6108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:45:23,528 - mmaction - INFO - Epoch [6][100/111]\tlr: 7.500e-05, eta: 0:10:50, time: 0.691, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.7327, loss: 0.7327\n",
      "2022-04-08 00:45:30,826 - mmaction - INFO - Saving checkpoint at 6 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.7 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:46:01,609 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:46:01,610 - mmaction - INFO - \n",
      "top1_acc\t0.7818\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:46:01,612 - mmaction - INFO - Epoch(val) [6][28]\ttop1_acc: 0.7818, top5_acc: 1.0000, loss_cls: 0.4892, loss: 0.4892\n",
      "2022-04-08 00:46:18,011 - mmaction - INFO - Epoch [7][20/111]\tlr: 6.545e-05, eta: 0:10:25, time: 0.820, data_time: 0.132, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5482, loss: 0.5482\n",
      "2022-04-08 00:46:31,801 - mmaction - INFO - Epoch [7][40/111]\tlr: 6.545e-05, eta: 0:10:13, time: 0.690, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4332, loss: 0.4332\n",
      "2022-04-08 00:46:45,642 - mmaction - INFO - Epoch [7][60/111]\tlr: 6.545e-05, eta: 0:10:02, time: 0.692, data_time: 0.000, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.5290, loss: 0.5290\n",
      "2022-04-08 00:46:59,459 - mmaction - INFO - Epoch [7][80/111]\tlr: 6.545e-05, eta: 0:09:50, time: 0.691, data_time: 0.000, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.2538, loss: 0.2538\n",
      "2022-04-08 00:47:13,216 - mmaction - INFO - Epoch [7][100/111]\tlr: 6.545e-05, eta: 0:09:38, time: 0.688, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5214, loss: 0.5214\n",
      "2022-04-08 00:47:20,496 - mmaction - INFO - Saving checkpoint at 7 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.7 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:47:51,681 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:47:51,683 - mmaction - INFO - \n",
      "top1_acc\t0.8000\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:47:51,684 - mmaction - INFO - Epoch(val) [7][28]\ttop1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5578, loss: 0.5578\n",
      "2022-04-08 00:48:07,943 - mmaction - INFO - Epoch [8][20/111]\tlr: 5.523e-05, eta: 0:09:14, time: 0.813, data_time: 0.150, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4175, loss: 0.4175\n",
      "2022-04-08 00:48:21,059 - mmaction - INFO - Epoch [8][40/111]\tlr: 5.523e-05, eta: 0:09:02, time: 0.656, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.3960, loss: 0.3960\n",
      "2022-04-08 00:48:34,127 - mmaction - INFO - Epoch [8][60/111]\tlr: 5.523e-05, eta: 0:08:50, time: 0.653, data_time: 0.000, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.2567, loss: 0.2567\n",
      "2022-04-08 00:48:47,168 - mmaction - INFO - Epoch [8][80/111]\tlr: 5.523e-05, eta: 0:08:37, time: 0.652, data_time: 0.000, memory: 2835, top1_acc: 0.7500, top5_acc: 1.0000, loss_cls: 0.5956, loss: 0.5956\n",
      "2022-04-08 00:49:00,194 - mmaction - INFO - Epoch [8][100/111]\tlr: 5.523e-05, eta: 0:08:24, time: 0.651, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.4899, loss: 0.4899\n",
      "2022-04-08 00:49:07,112 - mmaction - INFO - Saving checkpoint at 8 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.8 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:49:38,643 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:49:38,644 - mmaction - INFO - \n",
      "top1_acc\t0.8364\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:49:38,646 - mmaction - INFO - Epoch(val) [8][28]\ttop1_acc: 0.8364, top5_acc: 1.0000, loss_cls: 0.5330, loss: 0.5330\n",
      "2022-04-08 00:49:54,602 - mmaction - INFO - Epoch [9][20/111]\tlr: 4.477e-05, eta: 0:08:01, time: 0.798, data_time: 0.144, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.3992, loss: 0.3992\n",
      "2022-04-08 00:50:07,605 - mmaction - INFO - Epoch [9][40/111]\tlr: 4.477e-05, eta: 0:07:49, time: 0.650, data_time: 0.001, memory: 2835, top1_acc: 0.7750, top5_acc: 1.0000, loss_cls: 0.4382, loss: 0.4382\n",
      "2022-04-08 00:50:20,621 - mmaction - INFO - Epoch [9][60/111]\tlr: 4.477e-05, eta: 0:07:36, time: 0.651, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.4290, loss: 0.4290\n",
      "2022-04-08 00:50:33,654 - mmaction - INFO - Epoch [9][80/111]\tlr: 4.477e-05, eta: 0:07:24, time: 0.652, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3047, loss: 0.3047\n",
      "2022-04-08 00:50:46,683 - mmaction - INFO - Epoch [9][100/111]\tlr: 4.477e-05, eta: 0:07:11, time: 0.651, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2719, loss: 0.2719\n",
      "2022-04-08 00:50:53,595 - mmaction - INFO - Saving checkpoint at 9 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.7 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:51:24,495 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:51:24,496 - mmaction - INFO - \n",
      "top1_acc\t0.8364\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:51:24,498 - mmaction - INFO - Epoch(val) [9][28]\ttop1_acc: 0.8364, top5_acc: 1.0000, loss_cls: 0.4637, loss: 0.4637\n",
      "2022-04-08 00:51:41,326 - mmaction - INFO - Epoch [10][20/111]\tlr: 3.455e-05, eta: 0:06:49, time: 0.841, data_time: 0.187, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.3097, loss: 0.3097\n",
      "2022-04-08 00:51:54,420 - mmaction - INFO - Epoch [10][40/111]\tlr: 3.455e-05, eta: 0:06:37, time: 0.655, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.2690, loss: 0.2690\n",
      "2022-04-08 00:52:07,573 - mmaction - INFO - Epoch [10][60/111]\tlr: 3.455e-05, eta: 0:06:25, time: 0.658, data_time: 0.000, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.2009, loss: 0.2009\n",
      "2022-04-08 00:52:20,771 - mmaction - INFO - Epoch [10][80/111]\tlr: 3.455e-05, eta: 0:06:12, time: 0.660, data_time: 0.000, memory: 2835, top1_acc: 0.8750, top5_acc: 1.0000, loss_cls: 0.4013, loss: 0.4013\n",
      "2022-04-08 00:52:34,018 - mmaction - INFO - Epoch [10][100/111]\tlr: 3.455e-05, eta: 0:06:00, time: 0.662, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3989, loss: 0.3989\n",
      "2022-04-08 00:52:41,173 - mmaction - INFO - Saving checkpoint at 10 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.8 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:53:12,438 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:53:12,439 - mmaction - INFO - \n",
      "top1_acc\t0.8000\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:53:12,441 - mmaction - INFO - Epoch(val) [10][28]\ttop1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.5908, loss: 0.5908\n",
      "2022-04-08 00:53:28,541 - mmaction - INFO - Epoch [11][20/111]\tlr: 2.500e-05, eta: 0:05:38, time: 0.805, data_time: 0.134, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2518, loss: 0.2518\n",
      "2022-04-08 00:53:41,977 - mmaction - INFO - Epoch [11][40/111]\tlr: 2.500e-05, eta: 0:05:26, time: 0.672, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.3926, loss: 0.3926\n",
      "2022-04-08 00:53:55,463 - mmaction - INFO - Epoch [11][60/111]\tlr: 2.500e-05, eta: 0:05:14, time: 0.674, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2422, loss: 0.2422\n",
      "2022-04-08 00:54:09,011 - mmaction - INFO - Epoch [11][80/111]\tlr: 2.500e-05, eta: 0:05:01, time: 0.677, data_time: 0.000, memory: 2835, top1_acc: 0.8250, top5_acc: 1.0000, loss_cls: 0.3217, loss: 0.3217\n",
      "2022-04-08 00:54:22,602 - mmaction - INFO - Epoch [11][100/111]\tlr: 2.500e-05, eta: 0:04:49, time: 0.680, data_time: 0.000, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.3780, loss: 0.3780\n",
      "2022-04-08 00:54:29,838 - mmaction - INFO - Saving checkpoint at 11 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.7 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:55:01,202 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:55:01,203 - mmaction - INFO - \n",
      "top1_acc\t0.8909\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:55:01,205 - mmaction - INFO - Epoch(val) [11][28]\ttop1_acc: 0.8909, top5_acc: 1.0000, loss_cls: 0.2615, loss: 0.2615\n",
      "2022-04-08 00:55:17,660 - mmaction - INFO - Epoch [12][20/111]\tlr: 1.654e-05, eta: 0:04:28, time: 0.823, data_time: 0.148, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2321, loss: 0.2321\n",
      "2022-04-08 00:55:31,156 - mmaction - INFO - Epoch [12][40/111]\tlr: 1.654e-05, eta: 0:04:16, time: 0.675, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2572, loss: 0.2572\n",
      "2022-04-08 00:55:44,684 - mmaction - INFO - Epoch [12][60/111]\tlr: 1.654e-05, eta: 0:04:03, time: 0.676, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2598, loss: 0.2598\n",
      "2022-04-08 00:55:58,236 - mmaction - INFO - Epoch [12][80/111]\tlr: 1.654e-05, eta: 0:03:51, time: 0.678, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2226, loss: 0.2226\n",
      "2022-04-08 00:56:11,807 - mmaction - INFO - Epoch [12][100/111]\tlr: 1.654e-05, eta: 0:03:38, time: 0.679, data_time: 0.000, memory: 2835, top1_acc: 0.8500, top5_acc: 1.0000, loss_cls: 0.2864, loss: 0.2864\n",
      "2022-04-08 00:56:19,005 - mmaction - INFO - Saving checkpoint at 12 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.8 task/s, elapsed: 20s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:56:50,005 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:56:50,006 - mmaction - INFO - \n",
      "top1_acc\t0.8545\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:56:50,008 - mmaction - INFO - Epoch(val) [12][28]\ttop1_acc: 0.8545, top5_acc: 1.0000, loss_cls: 0.2637, loss: 0.2637\n",
      "2022-04-08 00:57:06,511 - mmaction - INFO - Epoch [13][20/111]\tlr: 9.549e-06, eta: 0:03:18, time: 0.825, data_time: 0.150, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2457, loss: 0.2457\n",
      "2022-04-08 00:57:20,010 - mmaction - INFO - Epoch [13][40/111]\tlr: 9.549e-06, eta: 0:03:05, time: 0.675, data_time: 0.001, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.1283, loss: 0.1283\n",
      "2022-04-08 00:57:33,527 - mmaction - INFO - Epoch [13][60/111]\tlr: 9.549e-06, eta: 0:02:53, time: 0.676, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2692, loss: 0.2692\n",
      "2022-04-08 00:57:47,085 - mmaction - INFO - Epoch [13][80/111]\tlr: 9.549e-06, eta: 0:02:40, time: 0.678, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2203, loss: 0.2203\n",
      "2022-04-08 00:58:00,641 - mmaction - INFO - Epoch [13][100/111]\tlr: 9.549e-06, eta: 0:02:28, time: 0.678, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2496, loss: 0.2496\n",
      "2022-04-08 00:58:07,841 - mmaction - INFO - Saving checkpoint at 13 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 00:58:37,617 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 00:58:37,618 - mmaction - INFO - \n",
      "top1_acc\t0.8545\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 00:58:37,620 - mmaction - INFO - Epoch(val) [13][28]\ttop1_acc: 0.8545, top5_acc: 1.0000, loss_cls: 0.3119, loss: 0.3119\n",
      "2022-04-08 00:58:53,812 - mmaction - INFO - Epoch [14][20/111]\tlr: 4.323e-06, eta: 0:02:07, time: 0.809, data_time: 0.134, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3167, loss: 0.3167\n",
      "2022-04-08 00:59:07,322 - mmaction - INFO - Epoch [14][40/111]\tlr: 4.323e-06, eta: 0:01:55, time: 0.675, data_time: 0.001, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2064, loss: 0.2064\n",
      "2022-04-08 00:59:20,856 - mmaction - INFO - Epoch [14][60/111]\tlr: 4.323e-06, eta: 0:01:42, time: 0.677, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.3490, loss: 0.3490\n",
      "2022-04-08 00:59:34,381 - mmaction - INFO - Epoch [14][80/111]\tlr: 4.323e-06, eta: 0:01:30, time: 0.676, data_time: 0.000, memory: 2835, top1_acc: 0.9000, top5_acc: 1.0000, loss_cls: 0.2774, loss: 0.2774\n",
      "2022-04-08 00:59:47,944 - mmaction - INFO - Epoch [14][100/111]\tlr: 4.323e-06, eta: 0:01:17, time: 0.678, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2432, loss: 0.2432\n",
      "2022-04-08 00:59:55,139 - mmaction - INFO - Saving checkpoint at 14 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.8 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 01:00:25,399 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 01:00:25,400 - mmaction - INFO - \n",
      "top1_acc\t0.8545\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 01:00:25,402 - mmaction - INFO - Epoch(val) [14][28]\ttop1_acc: 0.8545, top5_acc: 1.0000, loss_cls: 0.2554, loss: 0.2554\n",
      "2022-04-08 01:00:41,849 - mmaction - INFO - Epoch [15][20/111]\tlr: 1.093e-06, eta: 0:00:57, time: 0.822, data_time: 0.147, memory: 2835, top1_acc: 0.8000, top5_acc: 1.0000, loss_cls: 0.3674, loss: 0.3674\n",
      "2022-04-08 01:00:55,335 - mmaction - INFO - Epoch [15][40/111]\tlr: 1.093e-06, eta: 0:00:45, time: 0.674, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2326, loss: 0.2326\n",
      "2022-04-08 01:01:08,837 - mmaction - INFO - Epoch [15][60/111]\tlr: 1.093e-06, eta: 0:00:32, time: 0.675, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.2053, loss: 0.2053\n",
      "2022-04-08 01:01:22,388 - mmaction - INFO - Epoch [15][80/111]\tlr: 1.093e-06, eta: 0:00:19, time: 0.678, data_time: 0.000, memory: 2835, top1_acc: 0.9250, top5_acc: 1.0000, loss_cls: 0.3116, loss: 0.3116\n",
      "2022-04-08 01:01:35,953 - mmaction - INFO - Epoch [15][100/111]\tlr: 1.093e-06, eta: 0:00:06, time: 0.678, data_time: 0.000, memory: 2835, top1_acc: 0.9500, top5_acc: 1.0000, loss_cls: 0.2082, loss: 0.2082\n",
      "2022-04-08 01:01:43,139 - mmaction - INFO - Saving checkpoint at 15 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 55/55, 2.9 task/s, elapsed: 19s, ETA:     0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-08 01:02:13,020 - mmaction - INFO - Evaluating top_k_accuracy ...\n",
      "2022-04-08 01:02:13,021 - mmaction - INFO - \n",
      "top1_acc\t0.8545\n",
      "top5_acc\t1.0000\n",
      "2022-04-08 01:02:13,023 - mmaction - INFO - Epoch(val) [15][28]\ttop1_acc: 0.8545, top5_acc: 1.0000, loss_cls: 0.2477, loss: 0.2477\n"
     ]
    }
   ],
   "source": [
    "runner_kwargs = dict()\n",
    "runner.run(data_loaders, cfg.workflow, cfg.total_epochs, **runner_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8da66c68-4b16-4ffb-b79f-1847e3355d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td></td></tr><tr><td>top1_acc</td><td></td></tr><tr><td>top5_acc</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>0.0</td></tr><tr><td>top1_acc</td><td>0.85455</td></tr><tr><td>top5_acc</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cerulean-butterfly-10</strong>: <a href=\"https://wandb.ai/aswin_thiru/bsl/runs/irmgu9ef\" target=\"_blank\">https://wandb.ai/aswin_thiru/bsl/runs/irmgu9ef</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220408_003514-irmgu9ef/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e343d7a4-fcbb-482d-8002-f9233fba7510",
   "metadata": {},
   "source": [
    "## Unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52e95cd6-16cc-4bbd-94df-8a9dd18b6872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # init distributed env first, since logger depends on the dist info.\n",
    "# if args.launcher == 'none':\n",
    "#     distributed = False\n",
    "# else:\n",
    "#     distributed = True\n",
    "#     init_dist(args.launcher, **cfg.dist_params)\n",
    "#     _, world_size = get_dist_info()\n",
    "#     cfg.gpu_ids = range(world_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
