{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1a7aed7-6b2a-4081-8ed3-7847c97ac7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../Video-Swin-Transformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb5c1440-6b87-41d0-814a-b275108a97a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change teh working directory to a location that the code prefers\n",
    "os.chdir(\"../Video-Swin-Transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07e4a28c-4e43-4cde-8e9a-3d7236acb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist, set_random_seed\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmaction import __version__\n",
    "from mmaction.apis import train_model\n",
    "from mmaction.datasets import build_dataset\n",
    "from mmaction.models import build_model\n",
    "from mmaction.utils import collect_env, get_root_logger, register_module_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "befe8d30-137b-48ee-8fff-5f6c81f50d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO import test functions from mmcv and delete them from mmaction2\n",
    "try:\n",
    "    from mmcv.engine import multi_gpu_test, single_gpu_test\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    warnings.warn(\n",
    "        'DeprecationWarning: single_gpu_test, multi_gpu_test, '\n",
    "        'collect_results_cpu, collect_results_gpu from mmaction2 will be '\n",
    "        'deprecated. Please install mmcv through master branch.')\n",
    "    from mmaction.apis import multi_gpu_test, single_gpu_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4af724e-036d-455e-bfa4-c6f354e968b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the cofiguration and data file\n",
    "config_file = '../configs/kinetic_tiny_config.py'\n",
    "check_point_file = '../configs/swin_tiny_patch244_window877_kinetics400_1k.pth'\n",
    "# , \"model.backbone.pretrained=\"+check_point_file\n",
    "cmd_options = [config_file, \"--cfg-options\", \"model.backbone.use_checkpoint=True\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790667cc-bad1-43c0-9df4-a7e86c65dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(parse_options=None):\n",
    "    parser = argparse.ArgumentParser(description='Train a recognizer')\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    parser.add_argument('--work-dir', help='the dir to save logs and models')\n",
    "    parser.add_argument(\n",
    "        '--resume-from', help='the checkpoint file to resume from')\n",
    "    parser.add_argument(\n",
    "        '--validate',\n",
    "        action='store_true',\n",
    "        help='whether to evaluate the checkpoint during training')\n",
    "    parser.add_argument(\n",
    "        '--test-last',\n",
    "        action='store_true',\n",
    "        help='whether to test the checkpoint after training')\n",
    "    parser.add_argument(\n",
    "        '--test-best',\n",
    "        action='store_true',\n",
    "        help=('whether to test the best checkpoint (if applicable) after '\n",
    "              'training'))\n",
    "    group_gpus = parser.add_mutually_exclusive_group()\n",
    "    group_gpus.add_argument(\n",
    "        '--gpus',\n",
    "        type=int,\n",
    "        help='number of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    group_gpus.add_argument(\n",
    "        '--gpu-ids',\n",
    "        type=int,\n",
    "        nargs='+',\n",
    "        help='ids of gpus to use '\n",
    "        '(only applicable to non-distributed training)')\n",
    "    parser.add_argument('--seed', type=int, default=None, help='random seed')\n",
    "    parser.add_argument(\n",
    "        '--deterministic',\n",
    "        action='store_true',\n",
    "        help='whether to set deterministic options for CUDNN backend.')\n",
    "    parser.add_argument(\n",
    "        '--cfg-options',\n",
    "        nargs='+',\n",
    "        action=DictAction,\n",
    "        default={},\n",
    "        help='override some settings in the used config, the key-value pair '\n",
    "        'in xxx=yyy format will be merged into config file. For example, '\n",
    "        \"'--cfg-options model.backbone.depth=18 model.backbone.with_cp=True'\")\n",
    "    parser.add_argument(\n",
    "        '--launcher',\n",
    "        choices=['none', 'pytorch', 'slurm', 'mpi'],\n",
    "        default='none',\n",
    "        help='job launcher')\n",
    "    parser.add_argument('--local_rank', type=int, default=0)\n",
    "    \n",
    "    if parse_options is None: \n",
    "        args = parser.parse_args()\n",
    "    else:\n",
    "        args = parser.parse_args(parse_options)\n",
    "        \n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5631f204-c33d-433f-9b89-7f59293401ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(arg_options):\n",
    "    args = parse_args(arg_options)\n",
    "\n",
    "    cfg = Config.fromfile(args.config)\n",
    "\n",
    "    cfg.merge_from_dict(args.cfg_options)\n",
    "\n",
    "    # set cudnn_benchmark\n",
    "    if cfg.get('cudnn_benchmark', False):\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # work_dir is determined in this priority:\n",
    "    # CLI > config file > default (base filename)\n",
    "    if args.work_dir is not None:\n",
    "        # update configs according to CLI args if args.work_dir is not None\n",
    "        cfg.work_dir = args.work_dir\n",
    "    elif cfg.get('work_dir', None) is None:\n",
    "        # use config filename as default work_dir if cfg.work_dir is None\n",
    "        cfg.work_dir = osp.join('./work_dirs',\n",
    "                                osp.splitext(osp.basename(args.config))[0])\n",
    "    if args.resume_from is not None:\n",
    "        cfg.resume_from = args.resume_from\n",
    "    if args.gpu_ids is not None:\n",
    "        cfg.gpu_ids = args.gpu_ids\n",
    "    else:\n",
    "        cfg.gpu_ids = range(1) if args.gpus is None else range(args.gpus)\n",
    "\n",
    "    # init distributed env first, since logger depends on the dist info.\n",
    "    if args.launcher == 'none':\n",
    "        distributed = False\n",
    "    else:\n",
    "        distributed = True\n",
    "        init_dist(args.launcher, **cfg.dist_params)\n",
    "        _, world_size = get_dist_info()\n",
    "        cfg.gpu_ids = range(world_size)\n",
    "\n",
    "    # The flag is used to determine whether it is omnisource training\n",
    "    cfg.setdefault('omnisource', False)\n",
    "\n",
    "    # The flag is used to register module's hooks\n",
    "    cfg.setdefault('module_hooks', [])\n",
    "\n",
    "    # create work_dir\n",
    "    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "    # dump config\n",
    "    cfg.dump(osp.join(cfg.work_dir, osp.basename(args.config)))\n",
    "    # init logger before other steps\n",
    "    timestamp = time.strftime('%Y%m%d_%H%M%S', time.localtime())\n",
    "    log_file = osp.join(cfg.work_dir, f'{timestamp}.log')\n",
    "    logger = get_root_logger(log_file=log_file, log_level=cfg.log_level)\n",
    "\n",
    "    # init the meta dict to record some important information such as\n",
    "    # environment info and seed, which will be logged\n",
    "    meta = dict()\n",
    "    # log env info\n",
    "    env_info_dict = collect_env()\n",
    "    env_info = '\\n'.join([f'{k}: {v}' for k, v in env_info_dict.items()])\n",
    "    dash_line = '-' * 60 + '\\n'\n",
    "    logger.info('Environment info:\\n' + dash_line + env_info + '\\n' +\n",
    "                dash_line)\n",
    "    meta['env_info'] = env_info\n",
    "\n",
    "    # log some basic info\n",
    "    logger.info(f'Distributed training: {distributed}')\n",
    "    logger.info(f'Config: {cfg.pretty_text}')\n",
    "\n",
    "    # set random seeds\n",
    "    if args.seed is not None:\n",
    "        logger.info(f'Set random seed to {args.seed}, '\n",
    "                    f'deterministic: {args.deterministic}')\n",
    "        set_random_seed(args.seed, deterministic=args.deterministic)\n",
    "    cfg.seed = args.seed\n",
    "    meta['seed'] = args.seed\n",
    "    meta['config_name'] = osp.basename(args.config)\n",
    "    meta['work_dir'] = osp.basename(cfg.work_dir.rstrip('/\\\\'))\n",
    "\n",
    "    model = build_model(\n",
    "        cfg.model,\n",
    "        train_cfg=cfg.get('train_cfg'),\n",
    "        test_cfg=cfg.get('test_cfg'))\n",
    "\n",
    "    if len(cfg.module_hooks) > 0:\n",
    "        register_module_hooks(model, cfg.module_hooks)\n",
    "\n",
    "    if cfg.omnisource:\n",
    "        # If omnisource flag is set, cfg.data.train should be a list\n",
    "        assert isinstance(cfg.data.train, list)\n",
    "        datasets = [build_dataset(dataset) for dataset in cfg.data.train]\n",
    "    else:\n",
    "        datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "    if len(cfg.workflow) == 2:\n",
    "        # For simplicity, omnisource is not compatiable with val workflow,\n",
    "        # we recommend you to use `--validate`\n",
    "        assert not cfg.omnisource\n",
    "        if args.validate:\n",
    "            warnings.warn('val workflow is duplicated with `--validate`, '\n",
    "                          'it is recommended to use `--validate`. see '\n",
    "                          'https://github.com/open-mmlab/mmaction2/pull/123')\n",
    "        val_dataset = copy.deepcopy(cfg.data.val)\n",
    "        datasets.append(build_dataset(val_dataset))\n",
    "    if cfg.checkpoint_config is not None:\n",
    "        # save mmaction version, config file content and class names in\n",
    "        # checkpoints as meta data\n",
    "        cfg.checkpoint_config.meta = dict(\n",
    "            mmaction_version=__version__ + get_git_hash(digits=7),\n",
    "            config=cfg.pretty_text)\n",
    "\n",
    "    test_option = dict(test_last=args.test_last, test_best=args.test_best)\n",
    "    train_model(\n",
    "        model,\n",
    "        datasets,\n",
    "        cfg,\n",
    "        distributed=distributed,\n",
    "        validate=args.validate,\n",
    "        test=test_option,\n",
    "        timestamp=timestamp,\n",
    "        meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d97ef37d-cbae-4424-b0aa-81433a34115a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py\n",
      "../Video-Swin-Transformer/configs/_base_/default_runtime.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 01:18:01,474 - mmaction - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.12 | packaged by conda-forge | (default, Oct 12 2021, 21:59:51) [GCC 9.4.0]\n",
      "CUDA available: True\n",
      "GPU 0: Tesla T4\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Build cuda_11.6.r11.6/compiler.30794723_0\n",
      "GCC: gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\n",
      "PyTorch: 1.11.0a0+17540c5\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.3.3 (Git Hash N/A)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 11.6\n",
      "  - NVCC architecture flags: -gencode;arch=compute_52,code=sm_52;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_86,code=compute_86\n",
      "  - CuDNN 8.3.2  (built against CUDA 11.5)\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.6, CUDNN_VERSION=8.3.2, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS=-fno-gnu-unique -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=ON, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.12.0a0\n",
      "OpenCV: 4.5.5\n",
      "MMCV: 1.4.0\n",
      "MMCV Compiler: GCC 9.3\n",
      "MMCV CUDA Compiler: not available\n",
      "MMAction2: 0.15.0+db018fb\n",
      "------------------------------------------------------------\n",
      "\n",
      "2022-03-13 01:18:01,475 - mmaction - INFO - Distributed training: False\n",
      "2022-03-13 01:18:01,849 - mmaction - INFO - Config: model = dict(\n",
      "    type='Recognizer3D',\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer3D',\n",
      "        patch_size=(2, 4, 4),\n",
      "        embed_dim=96,\n",
      "        depths=[2, 2, 6, 2],\n",
      "        num_heads=[3, 6, 12, 24],\n",
      "        window_size=(8, 7, 7),\n",
      "        mlp_ratio=4.0,\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.1,\n",
      "        patch_norm=True,\n",
      "        use_checkpoint=True),\n",
      "    cls_head=dict(\n",
      "        type='I3DHead',\n",
      "        in_channels=768,\n",
      "        num_classes=400,\n",
      "        spatial_type='avg',\n",
      "        dropout_ratio=0.5),\n",
      "    test_cfg=dict(average_clips='prob', max_testing_views=4))\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=20, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "swin_tiny_path = '../Video-Swin-Transformer/configs/_base_/models/swin/swin_tiny.py'\n",
      "runtime_path = '../Video-Swin-Transformer/configs/_base_/default_runtime.py'\n",
      "dataset_type = 'VideoDataset'\n",
      "data_root = '../kinetics400_tiny'\n",
      "data_root_train = '../kinetics400_tiny/train'\n",
      "data_root_val = '../kinetics400_tiny/val'\n",
      "ann_file_train = '../kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
      "ann_file_val = '../kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
      "ann_file_test = '../kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_bgr=False)\n",
      "train_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(type='SampleFrames', clip_len=32, frame_interval=2, num_clips=1),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='RandomResizedCrop'),\n",
      "    dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "    dict(type='Flip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "]\n",
      "val_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=1,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 256)),\n",
      "    dict(type='CenterCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='DecordInit'),\n",
      "    dict(\n",
      "        type='SampleFrames',\n",
      "        clip_len=32,\n",
      "        frame_interval=2,\n",
      "        num_clips=4,\n",
      "        test_mode=True),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(type='Resize', scale=(-1, 224)),\n",
      "    dict(type='ThreeCrop', crop_size=224),\n",
      "    dict(type='Flip', flip_ratio=0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_bgr=False),\n",
      "    dict(type='FormatShape', input_format='NCTHW'),\n",
      "    dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "    dict(type='ToTensor', keys=['imgs'])\n",
      "]\n",
      "data = dict(\n",
      "    videos_per_gpu=8,\n",
      "    workers_per_gpu=4,\n",
      "    val_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    test_dataloader=dict(videos_per_gpu=1, workers_per_gpu=1),\n",
      "    train=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
      "        data_prefix='../kinetics400_tiny/train',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='RandomResizedCrop'),\n",
      "            dict(type='Resize', scale=(224, 224), keep_ratio=False),\n",
      "            dict(type='Flip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs', 'label'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
      "        data_prefix='../kinetics400_tiny/val',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=1,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 256)),\n",
      "            dict(type='CenterCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='VideoDataset',\n",
      "        ann_file='../kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
      "        data_prefix='../kinetics400_tiny/val',\n",
      "        pipeline=[\n",
      "            dict(type='DecordInit'),\n",
      "            dict(\n",
      "                type='SampleFrames',\n",
      "                clip_len=32,\n",
      "                frame_interval=2,\n",
      "                num_clips=4,\n",
      "                test_mode=True),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(type='Resize', scale=(-1, 224)),\n",
      "            dict(type='ThreeCrop', crop_size=224),\n",
      "            dict(type='Flip', flip_ratio=0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_bgr=False),\n",
      "            dict(type='FormatShape', input_format='NCTHW'),\n",
      "            dict(type='Collect', keys=['imgs', 'label'], meta_keys=[]),\n",
      "            dict(type='ToTensor', keys=['imgs'])\n",
      "        ]))\n",
      "evaluation = dict(\n",
      "    interval=5, metrics=['top_k_accuracy', 'mean_class_accuracy'])\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.001,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.02,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0),\n",
      "            backbone=dict(lr_mult=0.1))))\n",
      "lr_config = dict(\n",
      "    policy='CosineAnnealing',\n",
      "    min_lr=0,\n",
      "    warmup='linear',\n",
      "    warmup_by_epoch=True,\n",
      "    warmup_iters=2.5)\n",
      "total_epochs = 30\n",
      "work_dir = './work_dirs/k400_swin_tiny_patch244_window877.py'\n",
      "find_unused_parameters = False\n",
      "fp16 = None\n",
      "optimizer_config = dict(\n",
      "    type='DistOptimizerHook',\n",
      "    update_interval=4,\n",
      "    grad_clip=None,\n",
      "    coalesce=True,\n",
      "    bucket_size_mb=-1,\n",
      "    use_fp16=True)\n",
      "gpu_ids = range(0, 1)\n",
      "omnisource = False\n",
      "module_hooks = []\n",
      "\n",
      "2022-03-13 01:18:02,765 - mmaction - INFO - Start running, host: root@ip-10-0-0-32, work_dir: /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py\n",
      "2022-03-13 01:18:02,766 - mmaction - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) DistOptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2022-03-13 01:18:02,766 - mmaction - INFO - workflow: [('train', 1)], max: 30 epochs\n",
      "2022-03-13 01:18:02,767 - mmaction - INFO - Checkpoints will be saved to /workspace/Video-Swin-Transformer/work_dirs/k400_swin_tiny_patch244_window877.py by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 01:18:17,307 - mmaction - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 01:18:30,253 - mmaction - INFO - Saving checkpoint at 2 epochs\n",
      "2022-03-13 01:18:43,395 - mmaction - INFO - Saving checkpoint at 3 epochs\n",
      "2022-03-13 01:18:56,531 - mmaction - INFO - Saving checkpoint at 4 epochs\n",
      "2022-03-13 01:19:09,844 - mmaction - INFO - Saving checkpoint at 5 epochs\n",
      "2022-03-13 01:19:23,156 - mmaction - INFO - Saving checkpoint at 6 epochs\n",
      "2022-03-13 01:19:36,552 - mmaction - INFO - Saving checkpoint at 7 epochs\n",
      "2022-03-13 01:19:49,976 - mmaction - INFO - Saving checkpoint at 8 epochs\n",
      "2022-03-13 01:20:03,286 - mmaction - INFO - Saving checkpoint at 9 epochs\n",
      "2022-03-13 01:20:16,699 - mmaction - INFO - Saving checkpoint at 10 epochs\n",
      "2022-03-13 01:20:30,171 - mmaction - INFO - Saving checkpoint at 11 epochs\n",
      "2022-03-13 01:20:43,700 - mmaction - INFO - Saving checkpoint at 12 epochs\n",
      "2022-03-13 01:20:57,332 - mmaction - INFO - Saving checkpoint at 13 epochs\n",
      "2022-03-13 01:21:10,747 - mmaction - INFO - Saving checkpoint at 14 epochs\n",
      "2022-03-13 01:21:24,255 - mmaction - INFO - Saving checkpoint at 15 epochs\n",
      "2022-03-13 01:21:37,861 - mmaction - INFO - Saving checkpoint at 16 epochs\n",
      "2022-03-13 01:21:51,360 - mmaction - INFO - Saving checkpoint at 17 epochs\n",
      "2022-03-13 01:22:04,903 - mmaction - INFO - Saving checkpoint at 18 epochs\n",
      "2022-03-13 01:22:18,439 - mmaction - INFO - Saving checkpoint at 19 epochs\n",
      "2022-03-13 01:22:31,995 - mmaction - INFO - Saving checkpoint at 20 epochs\n",
      "2022-03-13 01:22:45,513 - mmaction - INFO - Saving checkpoint at 21 epochs\n",
      "2022-03-13 01:22:59,205 - mmaction - INFO - Saving checkpoint at 22 epochs\n",
      "2022-03-13 01:23:12,701 - mmaction - INFO - Saving checkpoint at 23 epochs\n",
      "2022-03-13 01:23:26,209 - mmaction - INFO - Saving checkpoint at 24 epochs\n",
      "2022-03-13 01:23:39,679 - mmaction - INFO - Saving checkpoint at 25 epochs\n",
      "2022-03-13 01:23:53,143 - mmaction - INFO - Saving checkpoint at 26 epochs\n",
      "2022-03-13 01:24:06,630 - mmaction - INFO - Saving checkpoint at 27 epochs\n",
      "2022-03-13 01:24:20,206 - mmaction - INFO - Saving checkpoint at 28 epochs\n",
      "2022-03-13 01:24:33,773 - mmaction - INFO - Saving checkpoint at 29 epochs\n",
      "2022-03-13 01:24:47,426 - mmaction - INFO - Saving checkpoint at 30 epochs\n"
     ]
    }
   ],
   "source": [
    "main(cmd_options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
